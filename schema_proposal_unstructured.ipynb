{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdf86ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.models.lite_llm import LiteLlm # For OpenAI support\n",
    "from google.adk.tools import ToolContext\n",
    "\n",
    "# Convenience libraries for working with Neo4j inside of Google ADK\n",
    "from neo4j_for_adk import graphdb, tool_success, tool_error\n",
    "\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66294ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement neo4j-for-adk (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for neo4j-for-adk\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install neo4j-for-adk --quiet\n",
    "%pip install neo4j --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e25a23ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience libraries for working with Neo4j inside of Google ADK\n",
    "from neo4j_for_adk import graphdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4782e6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Neo4j Connection Diagnostics ===\n",
      "\n",
      "1. Environment Variables:\n",
      "   NEO4J_URI: bolt://127.0.0.1:7687\n",
      "   NEO4J_USERNAME: neo4j\n",
      "   NEO4J_PASSWORD: ***********\n",
      "   NEO4J_DATABASE: neo4j\n",
      "\n",
      "2. Port Connectivity Test:\n",
      "   Neo4j Bolt (IPv4) (127.0.0.1:7687): ✅ OPEN\n",
      "   Neo4j Bolt (localhost) (localhost:7687): ✅ OPEN\n",
      "   Neo4j Browser (IPv4) (127.0.0.1:7474): ✅ OPEN\n",
      "   Neo4j Browser (localhost) (localhost:7474): ✅ OPEN\n",
      "\n",
      "3. Connection Attempts:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ IPv4 Direct: IPv4 Direct at 1768131129873\n",
      "   ✅ localhost: localhost at 1768131129924\n",
      "   ✅ Environment Vars: Env Vars at 1768131129944\n",
      "\n",
      "=== Recommendations ===\n",
      "If all connection attempts fail:\n",
      "1. Wait 30-60 seconds after container start for Neo4j to fully initialize\n",
      "2. Check Docker logs: docker logs neo4j\n",
      "3. Verify container is running: docker ps | grep neo4j\n",
      "4. Try recreating container if issues persist:\n",
      "   docker rm -f neo4j\n",
      "   docker run -d --name neo4j -p 7474:7474 -p 7687:7687 -e NEO4J_AUTH=neo4j/password123 neo4j:latest\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive Neo4j Diagnostics\n",
    "import os\n",
    "import socket\n",
    "import time\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "print(\"=== Neo4j Connection Diagnostics ===\\n\")\n",
    "\n",
    "# 1. Check environment variables\n",
    "print(\"1. Environment Variables:\")\n",
    "print(f\"   NEO4J_URI: {os.getenv('NEO4J_URI', 'Not set')}\")\n",
    "print(f\"   NEO4J_USERNAME: {os.getenv('NEO4J_USERNAME', 'Not set')}\")\n",
    "print(f\"   NEO4J_PASSWORD: {'*' * len(os.getenv('NEO4J_PASSWORD', '')) if os.getenv('NEO4J_PASSWORD') else 'Not set'}\")\n",
    "print(f\"   NEO4J_DATABASE: {os.getenv('NEO4J_DATABASE', 'Not set')}\\n\")\n",
    "\n",
    "# 2. Check if ports are open\n",
    "print(\"2. Port Connectivity Test:\")\n",
    "def check_port(host, port):\n",
    "    try:\n",
    "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        sock.settimeout(5)\n",
    "        result = sock.connect_ex((host, port))\n",
    "        sock.close()\n",
    "        return result == 0\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "ports_to_check = [\n",
    "    ('127.0.0.1', 7687, 'Neo4j Bolt (IPv4)'),\n",
    "    ('localhost', 7687, 'Neo4j Bolt (localhost)'),\n",
    "    ('127.0.0.1', 7474, 'Neo4j Browser (IPv4)'),\n",
    "    ('localhost', 7474, 'Neo4j Browser (localhost)')\n",
    "]\n",
    "\n",
    "for host, port, desc in ports_to_check:\n",
    "    is_open = check_port(host, port)\n",
    "    status = \"✅ OPEN\" if is_open else \"❌ CLOSED\"\n",
    "    print(f\"   {desc} ({host}:{port}): {status}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# 3. Try different connection approaches\n",
    "print(\"3. Connection Attempts:\")\n",
    "\n",
    "# Try with explicit IPv4\n",
    "try:\n",
    "    driver = GraphDatabase.driver(\"bolt://127.0.0.1:7687\", auth=(\"neo4j\", \"password123\"))\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"RETURN 'IPv4 Direct' as test, timestamp() as time\")\n",
    "        record = result.single()\n",
    "        print(f\"   ✅ IPv4 Direct: {record['test']} at {record['time']}\")\n",
    "    driver.close()\n",
    "except Exception as e:\n",
    "    print(f\"   ❌ IPv4 Direct: {type(e).__name__}: {str(e)[:100]}...\")\n",
    "\n",
    "# Try with localhost\n",
    "try:\n",
    "    driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password123\"))\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"RETURN 'localhost' as test, timestamp() as time\")\n",
    "        record = result.single()\n",
    "        print(f\"   ✅ localhost: {record['test']} at {record['time']}\")\n",
    "    driver.close()\n",
    "except Exception as e:\n",
    "    print(f\"   ❌ localhost: {type(e).__name__}: {str(e)[:100]}...\")\n",
    "\n",
    "# Try with environment variables\n",
    "try:\n",
    "    uri = os.getenv('NEO4J_URI', 'bolt://127.0.0.1:7687')\n",
    "    username = os.getenv('NEO4J_USERNAME', 'neo4j')\n",
    "    password = os.getenv('NEO4J_PASSWORD', 'password123')\n",
    "    driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"RETURN 'Env Vars' as test, timestamp() as time\")\n",
    "        record = result.single()\n",
    "        print(f\"   ✅ Environment Vars: {record['test']} at {record['time']}\")\n",
    "    driver.close()\n",
    "except Exception as e:\n",
    "    print(f\"   ❌ Environment Vars: {type(e).__name__}: {str(e)[:100]}...\")\n",
    "\n",
    "print(\"\\n=== Recommendations ===\")\n",
    "print(\"If all connection attempts fail:\")\n",
    "print(\"1. Wait 30-60 seconds after container start for Neo4j to fully initialize\")\n",
    "print(\"2. Check Docker logs: docker logs neo4j\")\n",
    "print(\"3. Verify container is running: docker ps | grep neo4j\")\n",
    "print(\"4. Try recreating container if issues persist:\")\n",
    "print(\"   docker rm -f neo4j\")\n",
    "print(\"   docker run -d --name neo4j -p 7474:7474 -p 7687:7687 -e NEO4J_AUTH=neo4j/password123 neo4j:latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0215f289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'success', 'query_result': [{'message': 'Neo4j is Ready!'}]}\n"
     ]
    }
   ],
   "source": [
    "# Check connection to Neo4j by sending a query\n",
    "\n",
    "neo4j_is_ready = graphdb.send_query(\"RETURN 'Neo4j is Ready!' as message\")\n",
    "\n",
    "print(neo4j_is_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60a978d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResponse(id='chatcmpl-Cwnxy1c6L5BhkRMG74HXKgGM2zfXH', created=1768131130, model='gpt-5-nano-2025-08-07', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Yes—I'm ready. What would you like to do? I can help with answers, writing, coding, data analysis, planning, and more. If you have a goal or task in mind, share the details and I’ll propose steps or start right away.\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=254, prompt_tokens=107, total_tokens=361, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=192, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')\n",
      "\n",
      "OpenAI is ready for use.\n"
     ]
    }
   ],
   "source": [
    "# Define Model Constants for easier use \n",
    "MODEL_GPT = \"openai/gpt-5-nano\"\n",
    "\n",
    "llm = LiteLlm(model=MODEL_GPT)\n",
    "\n",
    "# Test LLM with a direct call\n",
    "print(llm.llm_client.completion(model=llm.model, \n",
    "                                messages=[{\"role\": \"user\", \n",
    "                                           \"content\": \"Are you ready?\"}], \n",
    "                                tools=[]))\n",
    "\n",
    "print(\"\\nOpenAI is ready for use.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be2291d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_agent_role_and_goal = \"\"\"\n",
    "You are a top-tier algorithm designer for analyzing text files and proposing\n",
    "the kind of named entities that could be extracted which would be relevant \n",
    "for a user's goal.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f49a6628",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_agent_hints = \"\"\"\n",
    "Entities are people, places, things and qualities, but not quantities. \n",
    "Your goal is to propose a list of the type of entities, not the actual instances\n",
    "of entities.\n",
    "\n",
    "There are two general approaches to identifying types of entities:\n",
    "- well-known entities: these closely correlate with approved node labels in an existing graph schema\n",
    "- discovered entities: these may not exist in the graph schema, but appear consistently in the source text\n",
    "\n",
    "Design rules for well-known entities:\n",
    "- always use existing well-known entity types. For example, if there is a well-known type \"Person\", and people appear in the text, then propose \"Person\" as the type of entity.\n",
    "- prefer reusing existing entity types rather than creating new ones\n",
    "\n",
    "Design rules for discovered entities:\n",
    "- discovered entities are consistently mentioned in the text and are highly relevant to the user's goal\n",
    "- always look for entities that would provide more depth or breadth to the existing graph\n",
    "- for example, if the user goal is to represent social communities and the graph has \"Person\" nodes, look through the text to discover entities that are relevant like \"Hobby\" or \"Event\"\n",
    "- avoid quantitative types that may be better represented as a property on an existing entity or relationship.\n",
    "- for example, do not propose \"Age\" as a type of entity. That is better represented as an additional property \"age\" on a \"Person\".\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7740835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_agent_chain_of_thought_directions = \"\"\"\n",
    "Prepare for the task:\n",
    "- use the 'get_user_goal' tool to get the user goal\n",
    "- use the 'get_approved_files' tool to get the list of approved files\n",
    "- use the 'get_well_known_types' tool to get the approved node labels\n",
    "\n",
    "Think step by step:\n",
    "1. Sample some of the files using the 'sample_file' tool to understand the content\n",
    "2. Consider what well-known entities are mentioned in the text\n",
    "3. Discover entities that are frequently mentioned in the text that support the user's goal\n",
    "4. Use the 'set_proposed_entities' tool to save the list of well-known and discovered entity types\n",
    "5. Use the 'get_proposed_entities' tool to retrieve the proposed entities and present them to the user for their approval\n",
    "6. If the user approves, use the 'approve_proposed_entities' tool to finalize the entity types\n",
    "7. If the user does not approve, consider their feedback and iterate on the proposal\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae0bf776",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_agent_instruction = f\"\"\"\n",
    "{ner_agent_role_and_goal}\n",
    "{ner_agent_hints}\n",
    "{ner_agent_chain_of_thought_directions}\n",
    "\"\"\"\n",
    "\n",
    "#print(ner_agent_instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6423d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools to propose and approve entity types\n",
    "PROPOSED_ENTITIES = \"proposed_entity_types\"\n",
    "APPROVED_ENTITIES = \"approved_entity_types\"\n",
    "\n",
    "def set_proposed_entities(proposed_entity_types: list[str], tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Sets the list proposed entity types to extract from unstructured text.\"\"\"\n",
    "    tool_context.state[PROPOSED_ENTITIES] = proposed_entity_types\n",
    "    return tool_success(PROPOSED_ENTITIES, proposed_entity_types)\n",
    "\n",
    "def get_proposed_entities(tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Gets the list of proposed entity types to extract from unstructured text.\"\"\"\n",
    "    return tool_context.state.get(PROPOSED_ENTITIES, [])\n",
    "\n",
    "def approve_proposed_entities(tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Upon approval from user, records the proposed entity types as an approved list of entity types \n",
    "\n",
    "    Only call this tool if the user has explicitly approved the suggested files.\n",
    "    \"\"\"\n",
    "    if PROPOSED_ENTITIES not in tool_context.state:\n",
    "        return tool_error(\"No proposed entity types to approve. Please set proposed entities first, ask for user approval, then call this tool.\")\n",
    "    tool_context.state[APPROVED_ENTITIES] = tool_context.state.get(PROPOSED_ENTITIES)\n",
    "    return tool_success(APPROVED_ENTITIES, tool_context.state[APPROVED_ENTITIES])\n",
    "\n",
    "def get_approved_entities(tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Get the approved list of entity types to extract from unstructured text.\"\"\"\n",
    "    return tool_context.state.get(APPROVED_ENTITIES, [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fad3bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_well_known_types(tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Gets the approved labels that represent well-known entity types in the graph schema.\"\"\"\n",
    "    construction_plan = tool_context.state.get(\"approved_construction_plan\", {})\n",
    "    # approved labels are the keys for each construction plan entry where `construction_type` is \"node\"\n",
    "    approved_labels = {entry[\"label\"] for entry in construction_plan.values() if entry[\"construction_type\"] == \"node\"}\n",
    "    return tool_success(\"approved_labels\", approved_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a68dfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import get_approved_user_goal, get_approved_files, sample_file\n",
    "ner_agent_tools = [\n",
    "    get_approved_user_goal, get_approved_files, sample_file,\n",
    "    get_well_known_types,\n",
    "    set_proposed_entities,\n",
    "    approve_proposed_entities\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75670193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Gothenburg Table Reviews\n",
      "\n",
      "Scraped from https://www.between2furns.com/Gothenburg-Table/dp/B0BQJWJWJW\n",
      "\n",
      "## Rating: ★★★★★ (5/5)\n",
      "This table is the centerpiece of our dining room! The modern design is stunning yet timeless, and the quality is exceptional. We've had it for 6 months now and it still looks brand new despite daily use with two kids. Assembly took about an hour with two people. The surface is easy to clean and surprisingly resistant to scratches. Highly recommend!\n",
      "\n",
      "- @akollegger (Cambridge)\n",
      "\n",
      "---\n",
      "\n",
      "## Rating: ★★★☆☆ (3/5)\n",
      "The Gothenburg Table looks beautiful, I'll give it that. But assembly was a nightmare - some of the pre-drilled holes didn't line up properly and I had to drill new ones. Once assembled, it's sturdy enough, but I expected better quality control for this price point. The table top also shows fingerprints very easily which is annoying for daily use.\n",
      "\n",
      "- @furniture_lover92 (Seattle)\n",
      "\n",
      "---\n",
      "\n",
      "## Rating: ★★★★☆ (4/5)\n",
      "love love LOVE the look of this table!! perfect size for my apartment and the finish is gorgeous. took off a star because it was kinda complicated to put together and the instructions were confusing. but now that it's built it's perfect and all my friends are jealous. definitely worth the struggle lol\n",
      "\n",
      "- @designer_dave (Portland)\n",
      "\n",
      "---\n",
      "\n",
      "## Rating: ★★★★★ (5/5)\n",
      "As someone who entertains frequently, I needed a table that was both functional and aesthetically pleasing. The Gothenburg Table delivers on both counts. The dimensions (180cm x 90cm) are perfect for seating 6-8 people comfortably. The solid wood construction gives it a substantial feel, and the joinery is impeccable. The finish has a subtle matte quality that highlights the natural grain patterns. Assembly was straightforward with clear instructions. This table will clearly last for decades.\n",
      "\n",
      "- @home_chef (Chicago)\n",
      "\n",
      "---\n",
      "\n",
      "## Rating: ★★☆☆☆ (2/5)\n",
      "Disappointed with this purchase. The table arrived with a small dent on one edge, and while customer service was helpful in sending a replacement part, it was a hassle to deal with. The table also wobbles slightly on my hardwood floor despite multiple attempts to adjust it. For the price, I expected better quality control.\n",
      "\n",
      "- @diydan (Austin)\n",
      "\n",
      "---\n",
      "\n",
      "## Rating: ★★★★★ (5/5)\n",
      "Perfect table for our family of four! We've been using it daily for meals, homework, and game nights for the past year. It's held up beautifully with no signs of wear. The surface cleans easily and has resisted stains from art projects and spilled drinks. Assembly was straightforward and the included tools were adequate. The design is simple yet elegant - exactly what we wanted.\n",
      "\n",
      "- @familyfirst (Denver)\n",
      "\n",
      "---\n",
      "\n",
      "## Rating: ★★★★☆ (4/5)\n",
      "Good quality table that looks more expensive than it is. Assembly was straightforward but definitely needs two people. The wood grain is beautiful and the finish is smooth. I'm taking off one star because it scratches a bit more easily than I'd like, but overall I'm happy with the purchase.\n",
      "\n",
      "- @woodworker_amy (Portland)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_result = sample_file(file_path=\"product_reviews/gothenburg_table_reviews.md\",tool_context=None)\n",
    "\n",
    "print(file_result[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c0dd3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "NER_AGENT_NAME = \"ner_schema_agent_v1\"\n",
    "ner_schema_agent = Agent(\n",
    "    name=NER_AGENT_NAME,\n",
    "    description=\"Proposes the kind of named entities that could be extracted from text files.\",\n",
    "    model=llm,\n",
    "    instruction=ner_agent_instruction,\n",
    "    tools=ner_agent_tools, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d711635",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_agent_initial_state = {\n",
    "    \"approved_user_goal\": {\n",
    "        \"kind_of_graph\": \"supply chain analysis\",\n",
    "        \"description\": \"\"\"A multi-level bill of materials for manufactured products, useful for root cause analysis. \n",
    "        Add product reviews to start analysis from reported issues like quality, difficulty, or durability.\"\"\"\n",
    "    },\n",
    "    \"approved_files\": [\n",
    "        \"product_reviews/gothenburg_table_reviews.md\",\n",
    "        \"product_reviews/helsingborg_dresser_reviews.md\",\n",
    "        \"product_reviews/jonkoping_coffee_table_reviews.md\",\n",
    "        \"product_reviews/linkoping_bed_reviews.md\",\n",
    "        \"product_reviews/malmo_desk_reviews.md\",\n",
    "        \"product_reviews/norrkoping_nightstand_reviews.md\",\n",
    "        \"product_reviews/orebro_lamp_reviews.md\",\n",
    "        \"product_reviews/stockholm_chair_reviews.md\",\n",
    "        \"product_reviews/uppsala_sofa_reviews.md\",\n",
    "        \"product_reviews/vasteras_bookshelf_reviews.md\"\n",
    "    ],\n",
    "    \"approved_construction_plan\": {\n",
    "        \"Product\": {\n",
    "            \"construction_type\": \"node\",\n",
    "            \"label\": \"Product\",\n",
    "        },\n",
    "        \"Assembly\": {\n",
    "            \"construction_type\": \"node\",\n",
    "            \"label\": \"Assembly\",\n",
    "        },\n",
    "        \"Part\": {\n",
    "            \"construction_type\": \"node\",\n",
    "            \"label\": \"Part\",\n",
    "        },\n",
    "        \"Supplier\": {\n",
    "            \"construction_type\": \"node\",\n",
    "            \"label\": \"Supplier\",\n",
    "        }\n",
    "        # Relationship construction omitted, since it won't get used in this notebook\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c8459ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Query: Add product reviews to the knowledge graph to trace product complaints back through the manufacturing process.\n",
      "<<< Agent Response: Thanks. Here’s a concise proposal of entity types to extract for adding product reviews to the knowledge graph to trace complaints through manufacturing.\n",
      "\n",
      "What we already have in place\n",
      "- Well-known (existing) entity types (to reuse in the graph):\n",
      "  - Product\n",
      "  - Assembly\n",
      "  - Part\n",
      "  - Supplier\n",
      "\n",
      "- Discovered (new) entity types to add for depth and traceability:\n",
      "  - Review\n",
      "  - ReviewSource\n",
      "  - Issue\n",
      "  - IssueCategory\n",
      "  - ProcessStep\n",
      "  - Material\n",
      "  - Finish\n",
      "\n",
      "Rationale for these types\n",
      "- Review: Represents individual customer feedback entries extracted from reviews. Captures rating, text, author, date, and source context.\n",
      "- ReviewSource: Captures where the review came from (e.g., the review site or source platform). Helps trace provenance and assess source reliability.\n",
      "- Issue: A specific problem or complaint described in reviews (e.g., “assembly difficulties,” “drawer rails defective”). Enables root-cause analysis when linked to manufacturing steps or components.\n",
      "- IssueCategory: High-level categorization for issues (e.g., Assembly, Material, Finish, Hardware). Supports filtering and aggregation by issue type.\n",
      "- ProcessStep: Specific steps in the manufacturing/assembly process where issues originate or are detected (e.g., “assembly,” “quality control,” “packaging”).\n",
      "- Material: The raw materials used in a product (e.g., wood type, veneer, metal components) that could relate to durability or failure.\n",
      "- Finish: The final surface treatment or coating (e.g., matte finish, polyurethane) that may relate to wear, chipping, or customer perceptions.\n",
      "\n",
      "How these would relate (high-level guidance)\n",
      "- Product -> Review: has_review\n",
      "- Review -> ReviewSource: from_source or sourced_from\n",
      "- Review -> Issue: mentions_issue or reports_issue\n",
      "- Issue -> IssueCategory: categorized_as\n",
      "- Issue -> ProcessStep: linked_to_process_step (where the issue likely originated)\n",
      "- Product -> Part/Assembly: part_of or comprises\n",
      "- Part/Material/Finish -> Review: material_or_finish_related_to_issue (to trace where a failure or complaint might be linked)\n",
      "- Supplier: supplies parts or materials used in assemblies; issues might trace to suppliers via parts or components\n",
      "\n",
      "Example of how an item might be represented\n",
      "- Product: Gothenburg Table\n",
      "- Review: review text, rating, source, date\n",
      "- ReviewSource: Between2Furns (source URL)\n",
      "- Issue: “assembly holes misaligned,” “finish shows fingerprints”\n",
      "- IssueCategory: Assembly, Finish\n",
      "- ProcessStep: Assembly\n",
      "- Material: Solid wood, veneer (if mentioned)\n",
      "- Finish: Matte\n",
      "- Part/Assembly: Table top, legs, hardware\n",
      "\n",
      "Next step\n",
      "- Would you like me to finalize these proposed entity types as approved for extraction? If you approve, I’ll record them as approved and you can proceed with implementing extraction pipelines and graph synthesis based on these types. If you’d like adjustments (different discovered types or additional well-known types), tell me what to add or remove.\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "Session state:  {'approved_user_goal': {'kind_of_graph': 'supply chain analysis', 'description': 'A multi-level bill of materials for manufactured products, useful for root cause analysis. \\n        Add product reviews to start analysis from reported issues like quality, difficulty, or durability.'}, 'approved_files': ['product_reviews/gothenburg_table_reviews.md', 'product_reviews/helsingborg_dresser_reviews.md', 'product_reviews/jonkoping_coffee_table_reviews.md', 'product_reviews/linkoping_bed_reviews.md', 'product_reviews/malmo_desk_reviews.md', 'product_reviews/norrkoping_nightstand_reviews.md', 'product_reviews/orebro_lamp_reviews.md', 'product_reviews/stockholm_chair_reviews.md', 'product_reviews/uppsala_sofa_reviews.md', 'product_reviews/vasteras_bookshelf_reviews.md'], 'approved_construction_plan': {'Product': {'construction_type': 'node', 'label': 'Product'}, 'Assembly': {'construction_type': 'node', 'label': 'Assembly'}, 'Part': {'construction_type': 'node', 'label': 'Part'}, 'Supplier': {'construction_type': 'node', 'label': 'Supplier'}}, 'proposed_entity_types': ['Product', 'Assembly', 'Part', 'Supplier', 'Review', 'ReviewSource', 'Issue', 'IssueCategory', 'ProcessStep', 'Material', 'Finish']}\n",
      "\n",
      "Proposed entities:  ['Product', 'Assembly', 'Part', 'Supplier', 'Review', 'ReviewSource', 'Issue', 'IssueCategory', 'ProcessStep', 'Material', 'Finish']\n",
      "\n",
      "Awaiting approval.\n"
     ]
    }
   ],
   "source": [
    "from helper import make_agent_caller\n",
    "\n",
    "ner_agent_caller = await make_agent_caller(ner_schema_agent, ner_agent_initial_state)\n",
    "\n",
    "await ner_agent_caller.call(\"Add product reviews to the knowledge graph to trace product complaints back through the manufacturing process.\")\n",
    "\n",
    "# Alternatively, uncomment this line to get verbose output\n",
    "# await ner_agent_caller.call(\"Add product reviews.\", True)\n",
    "\n",
    "session_end = await ner_agent_caller.get_session()\n",
    "\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "print(\"\\nSession state: \", session_end.state)\n",
    "\n",
    "if PROPOSED_ENTITIES in session_end.state:\n",
    "    print(\"\\nProposed entities: \", session_end.state[PROPOSED_ENTITIES])\n",
    "\n",
    "if APPROVED_ENTITIES in session_end.state:\n",
    "    print(\"\\nInappropriately approved entities: \", session_end.state[APPROVED_ENTITIES])\n",
    "else:\n",
    "    print(\"\\nAwaiting approval.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a58ffd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Query: Approve the proposed entities.\n",
      "<<< Agent Response: Approval recorded. The following entity types are now approved for extraction and graph integration:\n",
      "\n",
      "- Product\n",
      "- Assembly\n",
      "- Part\n",
      "- Supplier\n",
      "- Review\n",
      "- ReviewSource\n",
      "- Issue\n",
      "- IssueCategory\n",
      "- ProcessStep\n",
      "- Material\n",
      "- Finish\n",
      "\n",
      "What’s next (recommended plan)\n",
      "- Define a concrete data model (properties and relationships):\n",
      "  - Review: rating, text, author, date, source_ref\n",
      "  - ReviewSource: name, url\n",
      "  - Issue: description, severity/impact, notes\n",
      "  - IssueCategory: category label (e.g., Assembly, Material, Finish)\n",
      "  - ProcessStep: step name or stage (e.g., assembly, QC)\n",
      "  - Material: material_name, material_type, specifications\n",
      "  - Finish: finish_type, color, sheen\n",
      "  - Product/Assembly/Part/Supplier: capture relevant attributes and interconnections (e.g., Part_of, Uses, Supplied_by)\n",
      "\n",
      "- Pilot ingestion (pilot run):\n",
      "  - Use a subset of approved files (e.g., Gothenburg Table Reviews and Linköping Bed Reviews) to demonstrate:\n",
      "    - How a Review node links to a ReviewSource\n",
      "    - How Issues are extracted from review text and categorized\n",
      "    - How Parts/Materials/Finish relate to a Product or its Assembly\n",
      "  - Validate extraction quality, disambiguate naming (e.g., map “Linköping” vs “Linköping”), and tune entity recognition heuristics if needed\n",
      "\n",
      "- Schema mapping examples (high level):\n",
      "  - Product -> HAS_REVIEW -> Review\n",
      "  - Review -> FROM_SOURCE -> ReviewSource\n",
      "  - Review -> REPORTS_ISSUE -> Issue\n",
      "  - Issue -> CATEGORIZED_AS -> IssueCategory\n",
      "  - Issue -> LINKED_TO_PROCESS_STEP -> ProcessStep\n",
      "  - Product -> COMPOSES -> Part\n",
      "  - Part -> MADE_OF -> Material\n",
      "  - Part/Finished product/Surface -> FINISHED_WITH -> Finish\n",
      "  - Supplier -> SUPPLIES -> Part (or Material)\n",
      "\n",
      "- Deliverables you’ll get:\n",
      "  - A documented schema mapping (entity types to properties and relationships)\n",
      "  - A small, test graph artifact (subset of data) showing the new entities and links\n",
      "  - A pipeline outline for ongoing ingestion from the approved reviews corpus\n",
      "\n",
      "Would you like me to proceed with a live pilot using the Gothenburg Table Reviews (and perhaps the Linköping Bed Reviews) to generate a sample graph fragment and validate the mappings? If you have preferred properties to include for each entity, or specific relationship names, tell me and I’ll incorporate them.\n",
      "Session state:  {'approved_user_goal': {'kind_of_graph': 'supply chain analysis', 'description': 'A multi-level bill of materials for manufactured products, useful for root cause analysis. \\n        Add product reviews to start analysis from reported issues like quality, difficulty, or durability.'}, 'approved_files': ['product_reviews/gothenburg_table_reviews.md', 'product_reviews/helsingborg_dresser_reviews.md', 'product_reviews/jonkoping_coffee_table_reviews.md', 'product_reviews/linkoping_bed_reviews.md', 'product_reviews/malmo_desk_reviews.md', 'product_reviews/norrkoping_nightstand_reviews.md', 'product_reviews/orebro_lamp_reviews.md', 'product_reviews/stockholm_chair_reviews.md', 'product_reviews/uppsala_sofa_reviews.md', 'product_reviews/vasteras_bookshelf_reviews.md'], 'approved_construction_plan': {'Product': {'construction_type': 'node', 'label': 'Product'}, 'Assembly': {'construction_type': 'node', 'label': 'Assembly'}, 'Part': {'construction_type': 'node', 'label': 'Part'}, 'Supplier': {'construction_type': 'node', 'label': 'Supplier'}}, 'proposed_entity_types': ['Product', 'Assembly', 'Part', 'Supplier', 'Review', 'ReviewSource', 'Issue', 'IssueCategory', 'ProcessStep', 'Material', 'Finish'], 'approved_entity_types': ['Product', 'Assembly', 'Part', 'Supplier', 'Review', 'ReviewSource', 'Issue', 'IssueCategory', 'ProcessStep', 'Material', 'Finish']}\n",
      "\n",
      "Approved entities:  ['Product', 'Assembly', 'Part', 'Supplier', 'Review', 'ReviewSource', 'Issue', 'IssueCategory', 'ProcessStep', 'Material', 'Finish']\n"
     ]
    }
   ],
   "source": [
    "await ner_agent_caller.call(\"Approve the proposed entities.\")\n",
    "\n",
    "session_end = await ner_agent_caller.get_session()\n",
    "\n",
    "ner_end_state = session_end.state if session_end else {}\n",
    "\n",
    "print(\"Session state: \", ner_end_state)\n",
    "\n",
    "if APPROVED_ENTITIES in ner_end_state:\n",
    "    print(\"\\nApproved entities: \", ner_end_state[APPROVED_ENTITIES])\n",
    "else:\n",
    "    print(\"\\nStill awaiting approval? That is weird. Please check the agent's state and the proposed entities.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f4227c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_agent_role_and_goal = \"\"\"\n",
    "  You are a top-tier algorithm designed for analyzing text files and proposing\n",
    "  the type of facts that could be extracted from text that would be relevant \n",
    "  for a user's goal. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "063e4362",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_agent_hints = \"\"\"\n",
    "  Do not propose specific individual facts, but instead propose the general type \n",
    "  of facts that would be relevant for the user's goal. \n",
    "  For example, do not propose \"ABK likes coffee\" but the general type of fact \"Person likes Beverage\".\n",
    "  \n",
    "  Facts are triplets of (subject, predicate, object) where the subject and object are\n",
    "  approved entity types, and the proposed predicate provides information about\n",
    "  how they are related. For example, a fact type could be (Person, likes, Beverage).\n",
    "\n",
    "  Design rules for facts:\n",
    "  - only use approved entity types as subjects or objects. Do not propose new types of entities\n",
    "  - the proposed predicate should describe the relationship between the approved subject and object\n",
    "  - the predicate should optimize for information that is relevant to the user's goal\n",
    "  - the predicate must appear in the source text. Do not guess.\n",
    "  - use the 'add_proposed_fact' tool to record each proposed fact type\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48badf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_agent_chain_of_thought_directions = \"\"\"\n",
    "    Prepare for the task:\n",
    "    - use the 'get_approved_user_goal' tool to get the user goal\n",
    "    - use the 'get_approved_files' tool to get the list of approved files\n",
    "    - use the 'get_approved_entities' tool to get the list of approved entity types\n",
    "\n",
    "    Think step by step:\n",
    "    1. Use the 'get_approved_user_goal' tool to get the user goal\n",
    "    2. Sample some of the approved files using the 'sample_file' tool to understand the content\n",
    "    3. Consider how subjects and objects are related in the text\n",
    "    4. Call the 'add_proposed_fact' tool for each type of fact you propose\n",
    "    5. Use the 'get_proposed_facts' tool to retrieve all the proposed facts\n",
    "    6. Present the proposed types of facts to the user, along with an explanation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a603ea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_agent_instruction = f\"\"\"\n",
    "{fact_agent_role_and_goal}\n",
    "{fact_agent_hints}\n",
    "{fact_agent_chain_of_thought_directions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c27f8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROPOSED_FACTS = \"proposed_fact_types\"\n",
    "APPROVED_FACTS = \"approved_fact_types\"\n",
    "\n",
    "def add_proposed_fact(approved_subject_label:str,\n",
    "                      proposed_predicate_label:str,\n",
    "                      approved_object_label:str,\n",
    "                      tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Add a proposed type of fact that could be extracted from the files.\n",
    "\n",
    "    A proposed fact type is a tuple of (subject, predicate, object) where\n",
    "    the subject and object are approved entity types and the predicate \n",
    "    is a proposed relationship label.\n",
    "\n",
    "    Args:\n",
    "      approved_subject_label: approved label of the subject entity type\n",
    "      proposed_predicate_label: label of the predicate\n",
    "      approved_object_label: approved label of the object entity type\n",
    "    \"\"\"\n",
    "    # Guard against invalid labels\n",
    "    approved_entities = tool_context.state.get(APPROVED_ENTITIES, [])\n",
    "    \n",
    "    if approved_subject_label not in approved_entities:\n",
    "        return tool_error(f\"Approved subject label {approved_subject_label} not found. Try again.\")\n",
    "    if approved_object_label not in approved_entities:\n",
    "        return tool_error(f\"Approved object label {approved_object_label} not found. Try again.\")\n",
    "    \n",
    "    current_predicates = tool_context.state.get(PROPOSED_FACTS, {})\n",
    "    current_predicates[proposed_predicate_label] = {\n",
    "        \"subject_label\": approved_subject_label,\n",
    "        \"predicate_label\": proposed_predicate_label,\n",
    "        \"object_label\": approved_object_label\n",
    "    }\n",
    "    tool_context.state[PROPOSED_FACTS] = current_predicates\n",
    "    return tool_success(PROPOSED_FACTS, current_predicates)\n",
    "    \n",
    "def get_proposed_facts(tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Get the proposed types of facts that could be extracted from the files.\"\"\"\n",
    "    return tool_context.state.get(PROPOSED_FACTS, {})\n",
    "\n",
    "\n",
    "def approve_proposed_facts(tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Upon user approval, records the proposed fact types as approved fact types\n",
    "\n",
    "    Only call this tool if the user has explicitly approved the proposed fact types.\n",
    "    \"\"\"\n",
    "    if PROPOSED_FACTS not in tool_context.state:\n",
    "        return tool_error(\"No proposed fact types to approve. Please set proposed facts first, ask for user approval, then call this tool.\")\n",
    "    tool_context.state[APPROVED_FACTS] = tool_context.state.get(PROPOSED_FACTS)\n",
    "    return tool_success(APPROVED_FACTS, tool_context.state[APPROVED_FACTS])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04f8a142",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_agent_tools = [\n",
    "    get_approved_user_goal, get_approved_files, \n",
    "    get_approved_entities,\n",
    "    sample_file,\n",
    "    add_proposed_fact,\n",
    "    get_proposed_facts,\n",
    "    approve_proposed_facts\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ad2d988",
   "metadata": {},
   "outputs": [],
   "source": [
    "FACT_AGENT_NAME = \"fact_type_extraction_agent_v1\"\n",
    "relevant_fact_agent = Agent(\n",
    "    name=FACT_AGENT_NAME,\n",
    "    description=\"Proposes the kind of relevant facts that could be extracted from text files.\",\n",
    "    model=llm,\n",
    "    instruction=fact_agent_instruction,\n",
    "    tools=fact_agent_tools, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "343c3086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Query: Propose fact types that can be found in the text.\n",
      "<<< Agent Response: Here are the general types of facts that could be extracted from the text, aligned with your goal (supply chain analysis / multi-level BOM context):\n",
      "\n",
      "- Product, Reviews, Review\n",
      "  - Captures that a Product has associated customer Reviews.\n",
      "  - Useful for linking products to user feedback and identifying common issues or praise.\n",
      "\n",
      "- Product, UsesMaterial, Material\n",
      "  - Captures which Materials are used by a Product.\n",
      "  - Helps trace BOM/components and material sourcing implications.\n",
      "\n",
      "- Product, HasFinish, Finish\n",
      "  - Captures the Finish applied to a Product (e.g., wood finish, paint).\n",
      "  - Important for material processing, sourcing, and quality control.\n",
      "\n",
      "- Product, HasProcessStep, ProcessStep\n",
      "  - Captures manufacturing or assembly steps involved in making the Product.\n",
      "  - Supports understanding of production flow and potential root-cause points in processes.\n",
      "\n",
      "Notes:\n",
      "- These fact types were proposed based on sample content from the Stockholm Chair Reviews and Malmö Desk Reviews, using approved entity types such as Product, Review, Material, Finish, and ProcessStep.\n",
      "- If you want the predicates to align with exact terms that appear in your source texts (e.g., specific phrases used in the docs), we can adjust the predicate labels accordingly.\n",
      "\n",
      "Would you like me to proceed with approving these proposed fact types, or refine them further (e.g., add additional predicates like part-supplier relationships, or link reviews to specific review sources)?\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "Session state:  {'approved_user_goal': {'kind_of_graph': 'supply chain analysis', 'description': 'A multi-level bill of materials for manufactured products, useful for root cause analysis. \\n        Add product reviews to start analysis from reported issues like quality, difficulty, or durability.'}, 'approved_files': ['product_reviews/gothenburg_table_reviews.md', 'product_reviews/helsingborg_dresser_reviews.md', 'product_reviews/jonkoping_coffee_table_reviews.md', 'product_reviews/linkoping_bed_reviews.md', 'product_reviews/malmo_desk_reviews.md', 'product_reviews/norrkoping_nightstand_reviews.md', 'product_reviews/orebro_lamp_reviews.md', 'product_reviews/stockholm_chair_reviews.md', 'product_reviews/uppsala_sofa_reviews.md', 'product_reviews/vasteras_bookshelf_reviews.md'], 'approved_construction_plan': {'Product': {'construction_type': 'node', 'label': 'Product'}, 'Assembly': {'construction_type': 'node', 'label': 'Assembly'}, 'Part': {'construction_type': 'node', 'label': 'Part'}, 'Supplier': {'construction_type': 'node', 'label': 'Supplier'}}, 'proposed_entity_types': ['Product', 'Assembly', 'Part', 'Supplier', 'Review', 'ReviewSource', 'Issue', 'IssueCategory', 'ProcessStep', 'Material', 'Finish'], 'approved_entity_types': ['Product', 'Assembly', 'Part', 'Supplier', 'Review', 'ReviewSource', 'Issue', 'IssueCategory', 'ProcessStep', 'Material', 'Finish'], 'proposed_fact_types': {'Reviews': {'subject_label': 'Product', 'predicate_label': 'Reviews', 'object_label': 'Review'}, 'UsesMaterial': {'subject_label': 'Product', 'predicate_label': 'UsesMaterial', 'object_label': 'Material'}, 'HasFinish': {'subject_label': 'Product', 'predicate_label': 'HasFinish', 'object_label': 'Finish'}, 'HasProcessStep': {'subject_label': 'Product', 'predicate_label': 'HasProcessStep', 'object_label': 'ProcessStep'}}}\n",
      "\n",
      "Approved entities:  ['Product', 'Assembly', 'Part', 'Supplier', 'Review', 'ReviewSource', 'Issue', 'IssueCategory', 'ProcessStep', 'Material', 'Finish']\n",
      "\n",
      "Correctly proposed facts:  {'Reviews': {'subject_label': 'Product', 'predicate_label': 'Reviews', 'object_label': 'Review'}, 'UsesMaterial': {'subject_label': 'Product', 'predicate_label': 'UsesMaterial', 'object_label': 'Material'}, 'HasFinish': {'subject_label': 'Product', 'predicate_label': 'HasFinish', 'object_label': 'Finish'}, 'HasProcessStep': {'subject_label': 'Product', 'predicate_label': 'HasProcessStep', 'object_label': 'ProcessStep'}}\n",
      "\n",
      "Approved facts not found in session state, which is good.\n"
     ]
    }
   ],
   "source": [
    "# make a copy of the NER agent's end state to use as the initial state for the fact agent\n",
    "fact_agent_initial_state = ner_end_state.copy()\n",
    "\n",
    "fact_agent_caller = await make_agent_caller(relevant_fact_agent, fact_agent_initial_state)\n",
    "\n",
    "await fact_agent_caller.call(\"Propose fact types that can be found in the text.\")\n",
    "# await fact_agent_caller.call(\"Propose fact types that can be found in the text.\", True)\n",
    "\n",
    "session_end = await fact_agent_caller.get_session()\n",
    "\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "print(\"\\nSession state: \", session_end.state)\n",
    "\n",
    "print(\"\\nApproved entities: \", session_end.state.get(APPROVED_ENTITIES, []))\n",
    "\n",
    "# Check that the agent proposed facts\n",
    "if PROPOSED_FACTS in session_end.state:\n",
    "    print(\"\\nCorrectly proposed facts: \", session_end.state[PROPOSED_FACTS])\n",
    "else:\n",
    "    print(\"\\nProposed facts not found in session state. What went wrong?\")\n",
    "\n",
    "# Check that the agent did not inappropriately approve facts\n",
    "if APPROVED_FACTS in session_end.state:\n",
    "    print(\"\\nInappriately approved facts: \", session_end.state[APPROVED_FACTS])\n",
    "else:\n",
    "    print(\"\\nApproved facts not found in session state, which is good.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bded181f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Query: Approve the proposed fact types.\n",
      "<<< Agent Response: Approval complete.\n",
      "\n",
      "Approved fact types:\n",
      "- (Product, Reviews, Review)\n",
      "- (Product, UsesMaterial, Material)\n",
      "- (Product, HasFinish, Finish)\n",
      "- (Product, HasProcessStep, ProcessStep)\n",
      "\n",
      "What this means:\n",
      "- You can now extract facts from the approved files using these four relationship types between Product and the corresponding object types (Review, Material, Finish, ProcessStep).\n",
      "- Each extracted fact will reflect a product-related piece of information such as a review, materials used, finish applied, or manufacturing/assembly steps.\n",
      "\n",
      "Next steps (optional):\n",
      "- I can run an extraction pass on the approved files and return a small set of example facts to illustrate the results.\n",
      "- I can also build a simple mapping or schema outline showing how these fact types connect across multiple products (e.g., which materials and finishes are common across product families).\n",
      "Session state:  {'approved_user_goal': {'kind_of_graph': 'supply chain analysis', 'description': 'A multi-level bill of materials for manufactured products, useful for root cause analysis. \\n        Add product reviews to start analysis from reported issues like quality, difficulty, or durability.'}, 'approved_files': ['product_reviews/gothenburg_table_reviews.md', 'product_reviews/helsingborg_dresser_reviews.md', 'product_reviews/jonkoping_coffee_table_reviews.md', 'product_reviews/linkoping_bed_reviews.md', 'product_reviews/malmo_desk_reviews.md', 'product_reviews/norrkoping_nightstand_reviews.md', 'product_reviews/orebro_lamp_reviews.md', 'product_reviews/stockholm_chair_reviews.md', 'product_reviews/uppsala_sofa_reviews.md', 'product_reviews/vasteras_bookshelf_reviews.md'], 'approved_construction_plan': {'Product': {'construction_type': 'node', 'label': 'Product'}, 'Assembly': {'construction_type': 'node', 'label': 'Assembly'}, 'Part': {'construction_type': 'node', 'label': 'Part'}, 'Supplier': {'construction_type': 'node', 'label': 'Supplier'}}, 'proposed_entity_types': ['Product', 'Assembly', 'Part', 'Supplier', 'Review', 'ReviewSource', 'Issue', 'IssueCategory', 'ProcessStep', 'Material', 'Finish'], 'approved_entity_types': ['Product', 'Assembly', 'Part', 'Supplier', 'Review', 'ReviewSource', 'Issue', 'IssueCategory', 'ProcessStep', 'Material', 'Finish'], 'proposed_fact_types': {'Reviews': {'subject_label': 'Product', 'predicate_label': 'Reviews', 'object_label': 'Review'}, 'UsesMaterial': {'subject_label': 'Product', 'predicate_label': 'UsesMaterial', 'object_label': 'Material'}, 'HasFinish': {'subject_label': 'Product', 'predicate_label': 'HasFinish', 'object_label': 'Finish'}, 'HasProcessStep': {'subject_label': 'Product', 'predicate_label': 'HasProcessStep', 'object_label': 'ProcessStep'}}, 'approved_fact_types': {'Reviews': {'subject_label': 'Product', 'predicate_label': 'Reviews', 'object_label': 'Review'}, 'UsesMaterial': {'subject_label': 'Product', 'predicate_label': 'UsesMaterial', 'object_label': 'Material'}, 'HasFinish': {'subject_label': 'Product', 'predicate_label': 'HasFinish', 'object_label': 'Finish'}, 'HasProcessStep': {'subject_label': 'Product', 'predicate_label': 'HasProcessStep', 'object_label': 'ProcessStep'}}}\n",
      "\n",
      "Approved fact types:  {'Reviews': {'subject_label': 'Product', 'predicate_label': 'Reviews', 'object_label': 'Review'}, 'UsesMaterial': {'subject_label': 'Product', 'predicate_label': 'UsesMaterial', 'object_label': 'Material'}, 'HasFinish': {'subject_label': 'Product', 'predicate_label': 'HasFinish', 'object_label': 'Finish'}, 'HasProcessStep': {'subject_label': 'Product', 'predicate_label': 'HasProcessStep', 'object_label': 'ProcessStep'}}\n"
     ]
    }
   ],
   "source": [
    "await fact_agent_caller.call(\"Approve the proposed fact types.\")\n",
    "\n",
    "session_end = await fact_agent_caller.get_session()\n",
    "\n",
    "print(\"Session state: \", session_end.state)\n",
    "\n",
    "if APPROVED_FACTS in session_end.state:\n",
    "    print(\"\\nApproved fact types: \", session_end.state[APPROVED_FACTS])\n",
    "else:\n",
    "    print(\"\\nFailed to approve fact types.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
