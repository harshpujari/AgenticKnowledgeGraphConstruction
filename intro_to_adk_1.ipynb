{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa4a8f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b8a7e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install google-adk --quiet\n",
    "%pip install litellm --quiet\n",
    "%pip install python-dotenv --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cfda411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "297478bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.models.lite_llm import LiteLlm # For OpenAI support\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.genai import types # For creating message Content/Parts\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9e6a672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResponse(id='chatcmpl-ClRp92O40sg0hua6csCd1f5xi6yH7', created=1765424407, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Yes, I'm ready. How can I assist you today?\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=13, prompt_tokens=27, total_tokens=40, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')\n",
      "\n",
      "OpenAI is ready for use.\n"
     ]
    }
   ],
   "source": [
    "# Define Model Constants for easier use \n",
    "MODEL_GPT = \"openai/gpt-4o\"\n",
    "\n",
    "llm = LiteLlm(model=MODEL_GPT)\n",
    "\n",
    "# Test LLM with a direct call\n",
    "print(llm.llm_client.completion(model=llm.model, \n",
    "                                messages=[{\"role\": \"user\", \n",
    "                                           \"content\": \"Are you ready?\"}], \n",
    "                                tools=[]))\n",
    "\n",
    "print(\"\\nOpenAI is ready for use.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ffc90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## How to setup Neo4j connection using environment variables\n",
    "# docker run -d \\\n",
    "#   --name neo4j \\\n",
    "#   -p 7474:7474 -p 7687:7687 \\\n",
    "#   -e NEO4J_AUTH=neo4j/password123 \\\n",
    "#   neo4j:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ba3e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you are coming back after a session restart, start the container again\n",
    "# docker start neo4j or docker restart neo4j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c6ac28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add this to yor .env file\n",
    "# NEO4J_URI=bolt://localhost:7687\n",
    "# NEO4J_USERNAME=neo4j\n",
    "# NEO4J_PASSWORD=password123\n",
    "# NEO4J_DATABASE=neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f0e0227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement neo4j-for-adk (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for neo4j-for-adk\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install neo4j-for-adk --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbe7fd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience libraries for working with Neo4j inside of Google ADK\n",
    "from neo4j_for_adk import graphdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efbdb903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'success', 'query_result': [{'message': 'Neo4j is Ready!'}]}\n"
     ]
    }
   ],
   "source": [
    "# Sending a simple query to the database\n",
    "neo4j_is_ready = graphdb.send_query(\"RETURN 'Neo4j is Ready!' as message\")\n",
    "\n",
    "print(neo4j_is_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f7ae4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a basic tool -- send a parameterized cypher query\n",
    "def say_hello(person_name: str) -> dict:\n",
    "    \"\"\"Formats a welcome message to a named person. \n",
    "\n",
    "    Args:\n",
    "        person_name (str): the name of the person saying hello\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the results of the query.\n",
    "              Includes a 'status' key ('success' or 'error').\n",
    "              If 'success', includes a 'query_result' key with an array of result rows.\n",
    "              If 'error', includes an 'error_message' key.\n",
    "    \"\"\"\n",
    "    return graphdb.send_query(\"RETURN 'Hello to you, ' + $person_name AS reply\",\n",
    "    {\n",
    "        \"person_name\": person_name\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab1dae50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'success', 'query_result': [{'reply': 'Hello to you, Harsh'}]}\n"
     ]
    }
   ],
   "source": [
    "# Example tool usage (optional test)\n",
    "print(say_hello(\"Harsh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ab6c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67e52095",
   "metadata": {},
   "source": [
    "**Optional Reading**\n",
    "\n",
    "- An `Agent` in Google ADK orchestrates the interaction between the user, the LLM, and the available tools\n",
    "\n",
    "- you configure it with several key parameters:\n",
    "    * `name`: A unique identifier for this agent (e.g., \"friendly_cypher_agent\\_v1\").  \n",
    "    * `model`: Specifies which LLM to use. you'll use the `llm` variable we defined above.  \n",
    "    * `description`: A summary of the agent's overall purpose. This is like public documentation that helps other agents decide when to delegate tasks to *this* agent.  \n",
    "    * `instruction`: Detailed guidance given to the LLM on how this agent should behave, its persona, goals, and specifically *how and when* to utilize its assigned `tools`.  \n",
    "    * `tools`: A list containing the actual Python tool functions the agent is allowed to use (e.g., `[say_hello]`).\n",
    "\n",
    "**Best Practice:** \n",
    "- Provide clear and specific `instruction` prompts. The more detailed the instructions, the better the LLM can understand its role and how to use its tools effectively. Be explicit about error handling if needed.\n",
    "- Choose descriptive `name` and `description` values. These are used internally by ADK and are vital for features like automatic delegation (covered later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa43b996",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
