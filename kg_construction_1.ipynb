{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6caf19e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "from google.adk.models.lite_llm import LiteLlm # For OpenAI support\n",
    "\n",
    "# Convenience libraries for working with Neo4j inside of Google ADK\n",
    "from neo4j_for_adk import graphdb, tool_success, tool_error\n",
    "\n",
    "from typing import Dict, Any\n",
    "\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7fce8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResponse(id='chatcmpl-CxcPVgPslTOyHTQBJkY54ZN2yKsBL', created=1768325037, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_deacdd5f6f', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Yes, I'm ready! How can I assist you today?\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=13, prompt_tokens=27, total_tokens=40, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')\n",
      "\n",
      "OpenAI ready.\n"
     ]
    }
   ],
   "source": [
    "# --- Define Model Constants for easier use ---\n",
    "MODEL_GPT_4O = \"openai/gpt-4o\"\n",
    "\n",
    "llm = LiteLlm(model=MODEL_GPT_4O)\n",
    "\n",
    "# Test LLM with a direct call\n",
    "print(llm.llm_client.completion(model=llm.model, messages=[{\"role\": \"user\", \"content\": \"Are you ready?\"}], tools=[]))\n",
    "\n",
    "print(\"\\nOpenAI ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e3ff41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'success', 'query_result': [{'message': 'Neo4j is Ready!'}]}\n"
     ]
    }
   ],
   "source": [
    "# Check connection to Neo4j by sending a query\n",
    "\n",
    "neo4j_is_ready = graphdb.send_query(\"RETURN 'Neo4j is Ready!' as message\")\n",
    "\n",
    "print(neo4j_is_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e96fa7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_uniqueness_constraint(\n",
    "    label: str,\n",
    "    unique_property_key: str,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Creates a uniqueness constraint for a node label and property key.\n",
    "    A uniqueness constraint ensures that no two nodes with the same label and property key have the same value.\n",
    "    This improves the performance and integrity of data import and later queries.\n",
    "\n",
    "    Args:\n",
    "        label: The label of the node to create a constraint for.\n",
    "        unique_property_key: The property key that should have a unique value.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with a status key ('success' or 'error').\n",
    "        On error, includes an 'error_message' key.\n",
    "    \"\"\"    \n",
    "    # Use string formatting since Neo4j doesn't support parameterization of labels and property keys when creating a constraint\n",
    "    constraint_name = f\"{label}_{unique_property_key}_constraint\"\n",
    "    query = f\"\"\"CREATE CONSTRAINT `{constraint_name}` IF NOT EXISTS\n",
    "    FOR (n:`{label}`)\n",
    "    REQUIRE n.`{unique_property_key}` IS UNIQUE\"\"\"\n",
    "    results = graphdb.send_query(query)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea61303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nodes_from_csv(\n",
    "    source_file: str,\n",
    "    label: str,\n",
    "    unique_column_name: str,\n",
    "    properties: list[str],\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Batch loading of nodes from a CSV file\"\"\"\n",
    "\n",
    "    # load nodes from CSV file by merging on the unique_column_name value\n",
    "    query = f\"\"\"LOAD CSV WITH HEADERS FROM \"file:///\" + $source_file AS row\n",
    "    CALL (row) {{\n",
    "        MERGE (n:$($label) {{ {unique_column_name} : row[$unique_column_name] }})\n",
    "        FOREACH (k IN $properties | SET n[k] = row[k])\n",
    "    }} IN TRANSACTIONS OF 1000 ROWS\n",
    "    \"\"\"\n",
    "\n",
    "    results = graphdb.send_query(query, {\n",
    "        \"source_file\": source_file,\n",
    "        \"label\": label,\n",
    "        \"unique_column_name\": unique_column_name,\n",
    "        \"properties\": properties\n",
    "    })\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1adfc9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_nodes(node_construction: dict) -> dict:\n",
    "    \"\"\"Import nodes as defined by a node construction rule.\"\"\"\n",
    "\n",
    "    # create a uniqueness constraint for the unique_column\n",
    "    uniqueness_result = create_uniqueness_constraint(\n",
    "        node_construction[\"label\"],\n",
    "        node_construction[\"unique_column_name\"]\n",
    "    )\n",
    "\n",
    "    if (uniqueness_result[\"status\"] == \"error\"):\n",
    "        return uniqueness_result\n",
    "\n",
    "    # import nodes from csv\n",
    "    load_nodes_result = load_nodes_from_csv(\n",
    "        node_construction[\"source_file\"],\n",
    "        node_construction[\"label\"],\n",
    "        node_construction[\"unique_column_name\"],\n",
    "        node_construction[\"properties\"]\n",
    "    )\n",
    "\n",
    "    return load_nodes_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b9701ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_relationships(relationship_construction: dict) -> Dict[str, Any]:\n",
    "    \"\"\"Import relationships as defined by a relationship construction rule.\"\"\"\n",
    "\n",
    "    # load nodes from CSV file by merging on the unique_column_name value \n",
    "    from_node_column = relationship_construction[\"from_node_column\"]\n",
    "    to_node_column = relationship_construction[\"to_node_column\"]\n",
    "    query = f\"\"\"LOAD CSV WITH HEADERS FROM \"file:///\" + $source_file AS row\n",
    "    CALL (row) {{\n",
    "        MATCH (from_node:$($from_node_label) {{ {from_node_column} : row[$from_node_column] }}),\n",
    "              (to_node:$($to_node_label) {{ {to_node_column} : row[$to_node_column] }} )\n",
    "        MERGE (from_node)-[r:$($relationship_type)]->(to_node)\n",
    "        FOREACH (k IN $properties | SET r[k] = row[k])\n",
    "    }} IN TRANSACTIONS OF 1000 ROWS\n",
    "    \"\"\"\n",
    "    \n",
    "    results = graphdb.send_query(query, {\n",
    "        \"source_file\": relationship_construction[\"source_file\"],\n",
    "        \"from_node_label\": relationship_construction[\"from_node_label\"],\n",
    "        \"from_node_column\": relationship_construction[\"from_node_column\"],\n",
    "        \"to_node_label\": relationship_construction[\"to_node_label\"],\n",
    "        \"to_node_column\": relationship_construction[\"to_node_column\"],\n",
    "        \"relationship_type\": relationship_construction[\"relationship_type\"],\n",
    "        \"properties\": relationship_construction[\"properties\"]\n",
    "    })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79cf8b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_domain_graph(construction_plan: dict) -> Dict[str, Any]:\n",
    "    \"\"\"Construct a domain graph according to a construction plan.\"\"\"\n",
    "    # first, import nodes\n",
    "    node_constructions = [value for value in construction_plan.values() if value['construction_type'] == 'node']\n",
    "    for node_construction in node_constructions:\n",
    "        import_nodes(node_construction)\n",
    "\n",
    "    # second, import relationships\n",
    "    relationship_constructions = [value for value in construction_plan.values() if value['construction_type'] == 'relationship']\n",
    "    for relationship_construction in relationship_constructions:\n",
    "        import_relationships(relationship_construction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
