{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90d50ff7",
   "metadata": {},
   "source": [
    "\n",
    "- Input: `approved_user_goal`, `approved_files`\n",
    "- Output: `approved_construction_plan`\n",
    "- Tools: `get_approved_user_goal`, `get_approved_files`, `sample_file`, \n",
    "        `propose_node_construction`, `propose_relationship_construction`, \n",
    "        `get_proposed_construction_plan`,`approve_proposed_construction_plan`\n",
    "\n",
    "\n",
    "**Workflow**\n",
    "\n",
    "\n",
    "This workflow will use multiple agents to propose a construction plan for the knowledge graph.\n",
    "\n",
    "A top-level 'schema_refinement_loop' will coordinate three agents operating in a loop:\n",
    "1. A 'schema_proposal_agent' that proposes a schema and construction plan for the knowledge graph.\n",
    "2. A 'schema_critic_agent' that critiques the proposed schema and construction plan for the knowledge graph.\n",
    "3. A 'CheckStatusAndEscalate' agent that checks the feedback of the critic agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c74b819d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from google.adk.agents import LlmAgent, LoopAgent\n",
    "from google.adk.models.lite_llm import LiteLlm # For OpenAI support\n",
    "from google.adk.tools import ToolContext\n",
    "\n",
    "# For type hints\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# Convenience libraries for working with Neo4j inside of Google ADK\n",
    "from neo4j_for_adk import graphdb, tool_success, tool_error\n",
    "\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f135ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResponse(id='chatcmpl-CvmlNuCDjjsQWBHSO2wkrxz670n8c', created=1767888177, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_deacdd5f6f', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Yes, I'm ready. How can I assist you today?\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=13, prompt_tokens=27, total_tokens=40, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')\n",
      "\n",
      "OpenAI ready.\n"
     ]
    }
   ],
   "source": [
    "# --- Define Model Constants for easier use ---\n",
    "MODEL_GPT_4O = \"openai/gpt-4o\"\n",
    "\n",
    "llm = LiteLlm(model=MODEL_GPT_4O)\n",
    "\n",
    "# Test LLM with a direct call\n",
    "print(llm.llm_client.completion(model=llm.model, messages=[{\"role\": \"user\", \"content\": \"Are you ready?\"}], tools=[]))\n",
    "\n",
    "print(\"\\nOpenAI ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d782601c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the use of {feedback} in the string.\n",
    "# Google ADK will replace this from session context if it exists.\n",
    "# Because feedback could be long, XML-like delimiters are included to clarify the content.\n",
    "proposal_agent_role_and_goal = \"\"\"\n",
    "    You are an expert at knowledge graph modeling with property graphs. Propose an appropriate\n",
    "    schema by specifying construction rules which transform approved files into nodes or relationships.\n",
    "    The resulting schema should describe a knowledge graph based on the user goal.\n",
    "    \n",
    "    Consider feedback if it is available: \n",
    "    <feedback>\n",
    "    {feedback}\n",
    "    </feedback> \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d6e0bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_agent_hints = \"\"\"\n",
    "    Every file in the approved files list will become either a node or a relationship.\n",
    "    Determining whether a file likely represents a node or a relationship is based\n",
    "    on a hint from the filename (is it a single thing or two things) and the\n",
    "    identifiers found within the file.\n",
    "\n",
    "    Because unique identifiers are so important for determining the structure of the graph,\n",
    "    always verify the uniqueness of suspected unique identifiers using the 'search_file' tool.\n",
    "\n",
    "    General guidance for identifying a node or a relationship:\n",
    "    - If the file name is singular and has only 1 unique identifier it is likely a node\n",
    "    - If the file name is a combination of two things, it is likely a full relationship\n",
    "    - If the file name sounds like a node, but there are multiple unique identifiers, that is likely a node with reference relationships\n",
    "\n",
    "    Design rules for nodes:\n",
    "    - Nodes will have unique identifiers. \n",
    "    - Nodes _may_ have identifiers that are used as reference relationships.\n",
    "\n",
    "    Design rules for relationships:\n",
    "    - Relationships appear in two ways: full relationships and reference relationships.\n",
    "\n",
    "    Full relationships:\n",
    "    - Full relationships appear in dedicated relationship files, often having a filename that references two entities\n",
    "    - Full relationships typically have references to a source and destination node.\n",
    "    - Full relationships _do not have_ unique identifiers, but instead have references to the primary keys of the source and destination nodes.\n",
    "    - The absence of a single, unique identifier is a strong indicator that a file is a full relationship.\n",
    "    \n",
    "    Reference relationships:\n",
    "    - Reference relationships appear as foreign key references in node files\n",
    "    - Reference relationship foreign key column names often hint at the destination node and relationship type\n",
    "    - References may be hierarchical container relationships, with terminology revealing parent-child, \"has\", \"contains\", membership, or similar relationship\n",
    "    - References may be peer relationships, that is often a self-reference to a similar class of nodes. For example, \"knows\" or \"see also\"\n",
    "\n",
    "    The resulting schema should be a connected graph, with no isolated components.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7aba6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_agent_chain_of_thought_directions = \"\"\"\n",
    "    Prepare for the task:\n",
    "    - get the user goal using the 'get_approved_user_goal' tool\n",
    "    - get the list of approved files using the 'get_approved_files' tool\n",
    "    - get the current construction plan using the 'get_proposed_construction_plan' tool\n",
    "\n",
    "    Think carefully, using tools to perform actions and reconsidering your actions when a tool returns an error:\n",
    "    1. For each approved file, consider whether it represents a node or relationship. Check the content for potential unique identifiers using the 'sample_file' tool.\n",
    "    2. For each identifier, verify that it is unique by using the 'search_file' tool.\n",
    "    3. Use the node vs relationship guidance for deciding whether the file represents a node or a relationship.\n",
    "    4. For a node file, propose a node construction using the 'propose_node_construction' tool. \n",
    "    5. If the node contains a reference relationship, use the 'propose_relationship_construction' tool to propose a relationship construction. \n",
    "    6. For a relationship file, propose a relationship construction using the 'propose_relationship_construction' tool\n",
    "    7. If you need to remove a construction, use the 'remove_node_construction' or 'remove_relationship_construction' tool\n",
    "    8. When you are done with construction proposals, use the 'get_proposed_construction_plan' tool to present the plan to the user\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95eb047a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    You are an expert at knowledge graph modeling with property graphs. Propose an appropriate\n",
      "    schema by specifying construction rules which transform approved files into nodes or relationships.\n",
      "    The resulting schema should describe a knowledge graph based on the user goal.\n",
      "\n",
      "    Consider feedback if it is available: \n",
      "    <feedback>\n",
      "    {feedback}\n",
      "    </feedback> \n",
      "\n",
      "\n",
      "    Every file in the approved files list will become either a node or a relationship.\n",
      "    Determining whether a file likely represents a node or a relationship is based\n",
      "    on a hint from the filename (is it a single thing or two things) and the\n",
      "    identifiers found within the file.\n",
      "\n",
      "    Because unique identifiers are so important for determining the structure of the graph,\n",
      "    always verify the uniqueness of suspected unique identifiers using the 'search_file' tool.\n",
      "\n",
      "    General guidance for identifying a node or a relationship:\n",
      "    - If the file name is singular and has only 1 unique identifier it is likely a node\n",
      "    - If the file name is a combination of two things, it is likely a full relationship\n",
      "    - If the file name sounds like a node, but there are multiple unique identifiers, that is likely a node with reference relationships\n",
      "\n",
      "    Design rules for nodes:\n",
      "    - Nodes will have unique identifiers. \n",
      "    - Nodes _may_ have identifiers that are used as reference relationships.\n",
      "\n",
      "    Design rules for relationships:\n",
      "    - Relationships appear in two ways: full relationships and reference relationships.\n",
      "\n",
      "    Full relationships:\n",
      "    - Full relationships appear in dedicated relationship files, often having a filename that references two entities\n",
      "    - Full relationships typically have references to a source and destination node.\n",
      "    - Full relationships _do not have_ unique identifiers, but instead have references to the primary keys of the source and destination nodes.\n",
      "    - The absence of a single, unique identifier is a strong indicator that a file is a full relationship.\n",
      "\n",
      "    Reference relationships:\n",
      "    - Reference relationships appear as foreign key references in node files\n",
      "    - Reference relationship foreign key column names often hint at the destination node and relationship type\n",
      "    - References may be hierarchical container relationships, with terminology revealing parent-child, \"has\", \"contains\", membership, or similar relationship\n",
      "    - References may be peer relationships, that is often a self-reference to a similar class of nodes. For example, \"knows\" or \"see also\"\n",
      "\n",
      "    The resulting schema should be a connected graph, with no isolated components.\n",
      "\n",
      "\n",
      "    Prepare for the task:\n",
      "    - get the user goal using the 'get_approved_user_goal' tool\n",
      "    - get the list of approved files using the 'get_approved_files' tool\n",
      "    - get the current construction plan using the 'get_proposed_construction_plan' tool\n",
      "\n",
      "    Think carefully, using tools to perform actions and reconsidering your actions when a tool returns an error:\n",
      "    1. For each approved file, consider whether it represents a node or relationship. Check the content for potential unique identifiers using the 'sample_file' tool.\n",
      "    2. For each identifier, verify that it is unique by using the 'search_file' tool.\n",
      "    3. Use the node vs relationship guidance for deciding whether the file represents a node or a relationship.\n",
      "    4. For a node file, propose a node construction using the 'propose_node_construction' tool. \n",
      "    5. If the node contains a reference relationship, use the 'propose_relationship_construction' tool to propose a relationship construction. \n",
      "    6. For a relationship file, propose a relationship construction using the 'propose_relationship_construction' tool\n",
      "    7. If you need to remove a construction, use the 'remove_node_construction' or 'remove_relationship_construction' tool\n",
      "    8. When you are done with construction proposals, use the 'get_proposed_construction_plan' tool to present the plan to the user\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# finally, combine all the prompt parts together\n",
    "proposal_agent_instruction = f\"\"\"\n",
    "{proposal_agent_role_and_goal}\n",
    "{proposal_agent_hints}\n",
    "{proposal_agent_chain_of_thought_directions}\n",
    "\"\"\"\n",
    "\n",
    "print(proposal_agent_instruction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "175980f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tools defined in previous notebook\n",
    "from tools import get_approved_user_goal, get_approved_files, sample_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fe2601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import get_neo4j_import_dir\n",
    "\n",
    "SEARCH_RESULTS = \"search_results\"\n",
    "\n",
    "# A simple grep-like tool for searching text files\n",
    "def search_file(file_path: str, query: str) -> dict:\n",
    "    \"\"\"\n",
    "    Searches any text file (markdown, csv, txt) for lines containing the given query string.\n",
    "    Simple grep-like functionality that works with any text file.\n",
    "    Search is always case insensitive.\n",
    "\n",
    "    Args:\n",
    "      file_path: Path to the file, relative to the Neo4j import directory.\n",
    "      query: The string to search for.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with 'status' ('success' or 'error').\n",
    "              If 'success', includes 'search_results' containing 'matching_lines'\n",
    "              (a list of dictionaries with 'line_number' and 'content' keys)\n",
    "              and basic metadata about the search.\n",
    "              If 'error', includes an 'error_message'.\n",
    "    \"\"\"\n",
    "    import_dir = Path(get_neo4j_import_dir())\n",
    "    p = import_dir / file_path\n",
    "\n",
    "    if not p.exists():\n",
    "        return tool_error(f\"File does not exist: {file_path}\")\n",
    "    if not p.is_file():\n",
    "        return tool_error(f\"Path is not a file: {file_path}\")\n",
    "\n",
    "    # Handle empty query - return no results\n",
    "    if not query:\n",
    "        return tool_success(SEARCH_RESULTS, {\n",
    "            \"metadata\": {\n",
    "                \"path\": file_path,\n",
    "                \"query\": query,\n",
    "                \"lines_found\": 0\n",
    "            },\n",
    "            \"matching_lines\": []\n",
    "        })\n",
    "\n",
    "    matching_lines = []\n",
    "    search_query = query.lower()\n",
    "    \n",
    "    try:\n",
    "        with open(p, 'r', encoding='utf-8') as file:\n",
    "            # Process the file line by line\n",
    "            for i, line in enumerate(file, 1):\n",
    "                line_to_check = line.lower()\n",
    "                if search_query in line_to_check:\n",
    "                    matching_lines.append({\n",
    "                        \"line_number\": i,\n",
    "                        \"content\": line.strip()  # Remove trailing newlines\n",
    "                    })\n",
    "                        \n",
    "    except Exception as e:\n",
    "        return tool_error(f\"Error reading or searching file {file_path}: {e}\")\n",
    "\n",
    "    # Prepare basic metadata\n",
    "    metadata = {\n",
    "        \"path\": file_path,\n",
    "        \"query\": query,\n",
    "        \"lines_found\": len(matching_lines)\n",
    "    }\n",
    "    \n",
    "    result_data = {\n",
    "        \"metadata\": metadata,\n",
    "        \"matching_lines\": matching_lines\n",
    "    }\n",
    "    return tool_success(SEARCH_RESULTS, result_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44a92694",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Tool: Propose Node Construction\n",
    "\n",
    "PROPOSED_CONSTRUCTION_PLAN = \"proposed_construction_plan\"\n",
    "NODE_CONSTRUCTION = \"node_construction\"\n",
    "\n",
    "def propose_node_construction(approved_file: str, proposed_label: str, unique_column_name: str, proposed_properties: list[str], tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Propose a node construction for an approved file that supports the user goal.\n",
    "\n",
    "    The construction will be added to the proposed construction plan dictionary under using proposed_label as the key.\n",
    "\n",
    "    The construction entry will be a dictionary with the following keys:\n",
    "    - construction_type: \"node\"\n",
    "    - source_file: the approved file to propose a node construction for\n",
    "    - label: the proposed label of the node\n",
    "    - unique_column_name: the name of the column that will be used to uniquely identify constructed nodes\n",
    "    - properties: A list of property names for the node, derived from column names in the approved file\n",
    "\n",
    "    Args:\n",
    "        approved_file: The approved file to propose a node construction for\n",
    "        proposed_label: The proposed label for constructed nodes (used as key in the construction plan)\n",
    "        unique_column_name: The name of the column that will be used to uniquely identify constructed nodes\n",
    "        proposed_properties: column names that should be imported as node properties\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing metadata about the content.\n",
    "                Includes a 'status' key ('success' or 'error').\n",
    "                If 'success', includes a \"node_construction\" key with the construction plan for the node\n",
    "                If 'error', includes an 'error_message' key.\n",
    "                The 'error_message' may have instructions about how to handle the error.\n",
    "    \"\"\"\n",
    "    # quick sanity check -- does the approved file have the unique column?\n",
    "    search_results = search_file(approved_file, unique_column_name)\n",
    "    if search_results[\"status\"] == \"error\":\n",
    "        return search_results # return the error\n",
    "    if search_results[\"search_results\"][\"metadata\"][\"lines_found\"] == 0:\n",
    "        return tool_error(f\"{approved_file} does not have the column {unique_column_name}. Check the file content and try again.\")\n",
    "\n",
    "    # get the current construction plan, or an empty one if none exists\n",
    "    construction_plan = tool_context.state.get(PROPOSED_CONSTRUCTION_PLAN, {})\n",
    "    node_construction_rule = {\n",
    "        \"construction_type\": \"node\",\n",
    "        \"source_file\": approved_file,\n",
    "        \"label\": proposed_label,\n",
    "        \"unique_column_name\": unique_column_name,\n",
    "        \"properties\": proposed_properties\n",
    "    }   \n",
    "    construction_plan[proposed_label] = node_construction_rule\n",
    "    tool_context.state[PROPOSED_CONSTRUCTION_PLAN] = construction_plan\n",
    "    return tool_success(NODE_CONSTRUCTION, node_construction_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6949a7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "RELATIONSHIP_CONSTRUCTION = \"relationship_construction\"\n",
    "\n",
    "def propose_relationship_construction(approved_file: str, proposed_relationship_type: str, \n",
    "    from_node_label: str,from_node_column: str, to_node_label:str, to_node_column: str, \n",
    "    proposed_properties: list[str], \n",
    "    tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Propose a relationship construction for an approved file that supports the user goal.\n",
    "\n",
    "    The construction will be added to the proposed construction plan dictionary under using proposed_relationship_type as the key.\n",
    "\n",
    "    Args:\n",
    "        approved_file: The approved file to propose a node construction for\n",
    "        proposed_relationship_type: The proposed label for constructed relationships\n",
    "        from_node_label: The label of the source node\n",
    "        from_node_column: The name of the column within the approved file that will be used to uniquely identify source nodes\n",
    "        to_node_label: The label of the target node\n",
    "        to_node_column: The name of the column within the approved file that will be used to uniquely identify target nodes\n",
    "        unique_column_name: The name of the column that will be used to uniquely identify target nodes\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing metadata about the content.\n",
    "                Includes a 'status' key ('success' or 'error').\n",
    "                If 'success', includes a \"relationship_construction\" key with the construction plan for the node\n",
    "                If 'error', includes an 'error_message' key.\n",
    "                The 'error_message' may have instructions about how to handle the error.\n",
    "    \"\"\"\n",
    "    # quick sanity check -- does the approved file have the from_node_column?\n",
    "    search_results = search_file(approved_file, from_node_column)\n",
    "    if search_results[\"status\"] == \"error\": \n",
    "        return search_results  # return the error if there is one\n",
    "    if search_results[\"search_results\"][\"metadata\"][\"lines_found\"] == 0:\n",
    "        return tool_error(f\"{approved_file} does not have the from node column {from_node_column}. Check the content of the file and reconsider the relationship.\")\n",
    "\n",
    "    # quick sanity check -- does the approved file have the to_node_column?\n",
    "    search_results = search_file(approved_file, to_node_column)\n",
    "    if search_results[\"status\"] == \"error\" or search_results[\"search_results\"][\"metadata\"][\"lines_found\"] == 0:\n",
    "        return tool_error(f\"{approved_file} does not have the to node column {to_node_column}. Check the content of the file and reconsider the relationship.\")\n",
    "\n",
    "    construction_plan = tool_context.state.get(PROPOSED_CONSTRUCTION_PLAN, {})\n",
    "    relationship_construction_rule = {\n",
    "        \"construction_type\": \"relationship\",\n",
    "        \"source_file\": approved_file,\n",
    "        \"relationship_type\": proposed_relationship_type,\n",
    "        \"from_node_label\": from_node_label,\n",
    "        \"from_node_column\": from_node_column,\n",
    "        \"to_node_label\": to_node_label,\n",
    "        \"to_node_column\": to_node_column,\n",
    "        \"properties\": proposed_properties\n",
    "    }   \n",
    "    construction_plan[proposed_relationship_type] = relationship_construction_rule\n",
    "    tool_context.state[PROPOSED_CONSTRUCTION_PLAN] = construction_plan\n",
    "    return tool_success(RELATIONSHIP_CONSTRUCTION, relationship_construction_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f1876c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool: Remove Node Construction\n",
    "def remove_node_construction(node_label: str, tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Remove a node construction from the proposed construction plan based on label.\n",
    "\n",
    "    Args:\n",
    "        node_label: The label of the node construction to remove\n",
    "        tool_context: The tool context\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing metadata about the content.\n",
    "                Includes a 'status' key ('success' or 'error').\n",
    "                If 'success', includes a 'node_construction_removed' key with the label of the removed node construction\n",
    "                If 'error', includes an 'error_message' key.\n",
    "                The 'error_message' may have instructions about how to handle the error.\n",
    "    \"\"\"\n",
    "    construction_plan = tool_context.state.get(PROPOSED_CONSTRUCTION_PLAN, {})\n",
    "    if node_label not in construction_plan:\n",
    "        return tool_success(\"node construction rule not found. removal not needed.\")\n",
    "\n",
    "    del construction_plan[node_label]\n",
    "\n",
    "    tool_context.state[PROPOSED_CONSTRUCTION_PLAN] = construction_plan\n",
    "    return tool_success(\"node_construction_removed\", node_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07728c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool: Remove Relationship Construction\n",
    "def remove_relationship_construction(relationship_type: str, tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Remove a relationship construction from the proposed construction plan based on type.\n",
    "\n",
    "    Args:\n",
    "        relationship_type: The type of the relationship construction to remove\n",
    "        tool_context: The tool context\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing metadata about the content.\n",
    "                Includes a 'status' key ('success' or 'error').\n",
    "                If 'success', includes a 'relationship_construction_removed' key with the type of the removed relationship construction\n",
    "                If 'error', includes an 'error_message' key.\n",
    "                The 'error_message' may have instructions about how to handle the error.\n",
    "    \"\"\"\n",
    "    construction_plan = tool_context.state.get(PROPOSED_CONSTRUCTION_PLAN, {})\n",
    "\n",
    "    if relationship_type not in construction_plan:\n",
    "        return tool_success(\"relationship construction rule not found. removal not needed.\")\n",
    "    \n",
    "    construction_plan.pop(relationship_type)\n",
    "    \n",
    "    tool_context.state[PROPOSED_CONSTRUCTION_PLAN] = construction_plan\n",
    "    return tool_success(\"relationship_construction_removed\", relationship_type) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21ab2e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool: Get Proposed construction Plan\n",
    "\n",
    "def get_proposed_construction_plan(tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Get the proposed construction plan, a dictionary of construction rules.\"\"\"\n",
    "    return tool_context.state.get(PROPOSED_CONSTRUCTION_PLAN, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c87bbe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool: Approve the proposed construction plan\n",
    "\n",
    "APPROVED_CONSTRUCTION_PLAN = \"approved_construction_plan\"\n",
    "\n",
    "def approve_proposed_construction_plan(tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Approve the proposed construction plan, if there is one.\"\"\"\n",
    "    if not PROPOSED_CONSTRUCTION_PLAN in tool_context.state:\n",
    "        return tool_error(\"No proposed construction plan found. Propose a plan first.\")\n",
    "    \n",
    "    tool_context.state[APPROVED_CONSTRUCTION_PLAN] = tool_context.state.get(PROPOSED_CONSTRUCTION_PLAN)\n",
    "    return tool_success(APPROVED_CONSTRUCTION_PLAN, tool_context.state[APPROVED_CONSTRUCTION_PLAN])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2262746c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tools for the structured schema proposal agent\n",
    "structured_schema_proposal_agent_tools = [\n",
    "    get_approved_user_goal, get_approved_files, \n",
    "    get_proposed_construction_plan,\n",
    "    sample_file, search_file,\n",
    "    propose_node_construction, propose_relationship_construction, \n",
    "    remove_node_construction, remove_relationship_construction\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ace5627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.agents.callback_context import CallbackContext\n",
    "\n",
    "# a helper function to log the agent name during execution\n",
    "def log_agent(callback_context: CallbackContext) -> None:\n",
    "    print(f\"\\n### Entering Agent: {callback_context.agent_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7044297",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA_AGENT_NAME = \"schema_proposal_agent_v1\"\n",
    "schema_proposal_agent = LlmAgent(\n",
    "    name=SCHEMA_AGENT_NAME,\n",
    "    description=\"Proposes a knowledge graph schema based on the user goal and approved file list\",\n",
    "    model=llm,\n",
    "    instruction=proposal_agent_instruction,\n",
    "    tools=structured_schema_proposal_agent_tools,\n",
    "    before_agent_callback=log_agent\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b01b535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import make_agent_caller\n",
    "\n",
    "# notice the initial state being passed in here to simulate previous workflow steps\n",
    "schema_proposal_caller = await make_agent_caller(schema_proposal_agent, {\n",
    "    \"feedback\": \"\",\n",
    "    \"approved_user_goal\": {\n",
    "        \"kind_of_graph\": \"supply chain analysis\",\n",
    "        \"description\": \"A multi-level bill of materials for manufactured products, useful for root cause analysis..\"\n",
    "    },\n",
    "    \"approved_files\": [\n",
    "        'assemblies.csv', \n",
    "        'parts.csv', \n",
    "        'part_supplier_mapping.csv', \n",
    "        'products.csv', \n",
    "        'suppliers.csv'\n",
    "    ]\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd79d239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience libraries for working with Neo4j inside of Google ADK\n",
    "from neo4j_for_adk import graphdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e041397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Query: How can these files be imported to construct the knowledge graph?\n",
      "\n",
      "### Entering Agent: schema_proposal_agent_v1\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "litellm.BadRequestError: OpenAIException - An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_VAoLuJIMMXxjEhhnQJU79njB, call_icc0peXZETWB0HHefBLlK7Xw, call_ZvEQq7QM1Nt5zJAertkjRQQr, call_uBJH2s3aLIhgq56CW4ePgexH, call_rur4SE6ng17L6voZiKeXlVEy",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/litellm/llms/openai/openai.py:836\u001b[39m, in \u001b[36mOpenAIChatCompletion.acompletion\u001b[39m\u001b[34m(self, messages, optional_params, litellm_params, provider_config, model, model_response, logging_obj, timeout, api_key, api_base, api_version, organization, client, max_retries, headers, drop_params, stream_options, fake_stream, shared_session)\u001b[39m\n\u001b[32m    823\u001b[39m logging_obj.pre_call(\n\u001b[32m    824\u001b[39m     \u001b[38;5;28minput\u001b[39m=data[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    825\u001b[39m     api_key=openai_aclient.api_key,\n\u001b[32m   (...)\u001b[39m\u001b[32m    833\u001b[39m     },\n\u001b[32m    834\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m836\u001b[39m headers, response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.make_openai_chat_completion_request(\n\u001b[32m    837\u001b[39m     openai_aclient=openai_aclient,\n\u001b[32m    838\u001b[39m     data=data,\n\u001b[32m    839\u001b[39m     timeout=timeout,\n\u001b[32m    840\u001b[39m     logging_obj=logging_obj,\n\u001b[32m    841\u001b[39m )\n\u001b[32m    842\u001b[39m stringified_response = response.model_dump()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/litellm/litellm_core_utils/logging_utils.py:190\u001b[39m, in \u001b[36mtrack_llm_api_timing.<locals>.decorator.<locals>.async_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/litellm/llms/openai/openai.py:460\u001b[39m, in \u001b[36mOpenAIChatCompletion.make_openai_chat_completion_request\u001b[39m\u001b[34m(self, openai_aclient, data, timeout, logging_obj)\u001b[39m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/litellm/llms/openai/openai.py:437\u001b[39m, in \u001b[36mOpenAIChatCompletion.make_openai_chat_completion_request\u001b[39m\u001b[34m(self, openai_aclient, data, timeout, logging_obj)\u001b[39m\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    436\u001b[39m     raw_response = (\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m openai_aclient.chat.completions.with_raw_response.create(\n\u001b[32m    438\u001b[39m             **data, timeout=timeout\n\u001b[32m    439\u001b[39m         )\n\u001b[32m    440\u001b[39m     )\n\u001b[32m    441\u001b[39m     end_time = time.time()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/openai/_legacy_response.py:381\u001b[39m, in \u001b[36masync_to_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    379\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m381\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[38;5;28;01mawait\u001b[39;00m func(*args, **kwargs))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:2678\u001b[39m, in \u001b[36mAsyncCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   2677\u001b[39m validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m2678\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   2679\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2680\u001b[39m     body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   2681\u001b[39m         {\n\u001b[32m   2682\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m   2683\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   2684\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m: audio,\n\u001b[32m   2685\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   2686\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m   2687\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m   2688\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m   2689\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m   2690\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m   2691\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m   2692\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   2693\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodalities\u001b[39m\u001b[33m\"\u001b[39m: modalities,\n\u001b[32m   2694\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m   2695\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   2696\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m: prediction,\n\u001b[32m   2697\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m   2698\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprompt_cache_key\u001b[39m\u001b[33m\"\u001b[39m: prompt_cache_key,\n\u001b[32m   2699\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprompt_cache_retention\u001b[39m\u001b[33m\"\u001b[39m: prompt_cache_retention,\n\u001b[32m   2700\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mreasoning_effort\u001b[39m\u001b[33m\"\u001b[39m: reasoning_effort,\n\u001b[32m   2701\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n\u001b[32m   2702\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33msafety_identifier\u001b[39m\u001b[33m\"\u001b[39m: safety_identifier,\n\u001b[32m   2703\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m   2704\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   2705\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m   2706\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   2707\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   2708\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n\u001b[32m   2709\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   2710\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   2711\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   2712\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m   2713\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   2714\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   2715\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mverbosity\u001b[39m\u001b[33m\"\u001b[39m: verbosity,\n\u001b[32m   2716\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mweb_search_options\u001b[39m\u001b[33m\"\u001b[39m: web_search_options,\n\u001b[32m   2717\u001b[39m         },\n\u001b[32m   2718\u001b[39m         completion_create_params.CompletionCreateParamsStreaming\n\u001b[32m   2719\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[32m   2720\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m completion_create_params.CompletionCreateParamsNonStreaming,\n\u001b[32m   2721\u001b[39m     ),\n\u001b[32m   2722\u001b[39m     options=make_request_options(\n\u001b[32m   2723\u001b[39m         extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   2724\u001b[39m     ),\n\u001b[32m   2725\u001b[39m     cast_to=ChatCompletion,\n\u001b[32m   2726\u001b[39m     stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   2727\u001b[39m     stream_cls=AsyncStream[ChatCompletionChunk],\n\u001b[32m   2728\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/openai/_base_client.py:1794\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1791\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1792\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1793\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1794\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/openai/_base_client.py:1594\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1593\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1594\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1596\u001b[39m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_VAoLuJIMMXxjEhhnQJU79njB, call_icc0peXZETWB0HHefBLlK7Xw, call_ZvEQq7QM1Nt5zJAertkjRQQr, call_uBJH2s3aLIhgq56CW4ePgexH, call_rur4SE6ng17L6voZiKeXlVEy\", 'type': 'invalid_request_error', 'param': 'messages.[7].role', 'code': None}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/litellm/main.py:607\u001b[39m, in \u001b[36macompletion\u001b[39m\u001b[34m(model, messages, functions, function_call, timeout, temperature, top_p, n, stream, stream_options, stop, max_tokens, max_completion_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, parallel_tool_calls, logprobs, top_logprobs, deployment_id, reasoning_effort, verbosity, safety_identifier, service_tier, base_url, api_version, api_key, model_list, extra_headers, thinking, web_search_options, shared_session, **kwargs)\u001b[39m\n\u001b[32m    606\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m asyncio.iscoroutine(init_response):\n\u001b[32m--> \u001b[39m\u001b[32m607\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m init_response\n\u001b[32m    608\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/litellm/llms/openai/openai.py:883\u001b[39m, in \u001b[36mOpenAIChatCompletion.acompletion\u001b[39m\u001b[34m(self, messages, optional_params, litellm_params, provider_config, model, model_response, logging_obj, timeout, api_key, api_base, api_version, organization, client, max_retries, headers, drop_params, stream_options, fake_stream, shared_session)\u001b[39m\n\u001b[32m    881\u001b[39m message = \u001b[38;5;28mgetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(e))\n\u001b[32m--> \u001b[39m\u001b[32m883\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    884\u001b[39m     status_code=status_code,\n\u001b[32m    885\u001b[39m     message=message,\n\u001b[32m    886\u001b[39m     headers=error_headers,\n\u001b[32m    887\u001b[39m     body=exception_body,\n\u001b[32m    888\u001b[39m )\n",
      "\u001b[31mOpenAIError\u001b[39m: Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_VAoLuJIMMXxjEhhnQJU79njB, call_icc0peXZETWB0HHefBLlK7Xw, call_ZvEQq7QM1Nt5zJAertkjRQQr, call_uBJH2s3aLIhgq56CW4ePgexH, call_rur4SE6ng17L6voZiKeXlVEy\", 'type': 'invalid_request_error', 'param': 'messages.[7].role', 'code': None}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m schema_proposal_caller.call(\u001b[33m\"\u001b[39m\u001b[33mHow can these files be imported to construct the knowledge graph?\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m session_end = \u001b[38;5;28;01mawait\u001b[39;00m schema_proposal_caller.get_session()\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/AgenticKnowledgeGraphConstruction/helper.py:55\u001b[39m, in \u001b[36mAgentCaller.call\u001b[39m\u001b[34m(self, query, verbose)\u001b[39m\n\u001b[32m     51\u001b[39m final_response_text = \u001b[33m\"\u001b[39m\u001b[33mAgent did not produce a final response.\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;66;03m# Default\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# Key Concept: run_async executes the agent logic and yields Events.\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# We iterate through events to find the final answer.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.runner.run_async(user_id=\u001b[38;5;28mself\u001b[39m.user_id, session_id=\u001b[38;5;28mself\u001b[39m.session_id, new_message=content):\n\u001b[32m     56\u001b[39m     \u001b[38;5;66;03m# You can uncomment the line below to see *all* events during execution\u001b[39;00m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[32m     58\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  [Event] Author: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent.author\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(event).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Final: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent.is_final_response()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Content: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent.content\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/google/adk/runners.py:505\u001b[39m, in \u001b[36mRunner.run_async\u001b[39m\u001b[34m(self, user_id, session_id, invocation_id, new_message, state_delta, run_config)\u001b[39m\n\u001b[32m    500\u001b[39m       \u001b[38;5;28;01mawait\u001b[39;00m _run_compaction_for_sliding_window(\n\u001b[32m    501\u001b[39m           \u001b[38;5;28mself\u001b[39m.app, session, \u001b[38;5;28mself\u001b[39m.session_service\n\u001b[32m    502\u001b[39m       )\n\u001b[32m    504\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(_run_with_trace(new_message, invocation_id)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    506\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/google/adk/runners.py:493\u001b[39m, in \u001b[36mRunner.run_async.<locals>._run_with_trace\u001b[39m\u001b[34m(new_message, invocation_id)\u001b[39m\n\u001b[32m    483\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    485\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    486\u001b[39m     \u001b[38;5;28mself\u001b[39m._exec_with_plugin(\n\u001b[32m    487\u001b[39m         invocation_context=invocation_context,\n\u001b[32m   (...)\u001b[39m\u001b[32m    491\u001b[39m     )\n\u001b[32m    492\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    494\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    495\u001b[39m \u001b[38;5;66;03m# Run compaction after all events are yielded from the agent.\u001b[39;00m\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# (We don't compact in the middle of an invocation, we only compact at\u001b[39;00m\n\u001b[32m    497\u001b[39m \u001b[38;5;66;03m# the end of an invocation.)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/google/adk/runners.py:722\u001b[39m, in \u001b[36mRunner._exec_with_plugin\u001b[39m\u001b[34m(self, invocation_context, session, execute_fn, is_live_call)\u001b[39m\n\u001b[32m    719\u001b[39m is_transcribing: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    721\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(execute_fn(invocation_context)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m722\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    723\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_live_call:\n\u001b[32m    724\u001b[39m       \u001b[38;5;28;01mif\u001b[39;00m event.partial \u001b[38;5;129;01mand\u001b[39;00m _is_transcription(event):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/google/adk/runners.py:482\u001b[39m, in \u001b[36mRunner.run_async.<locals>._run_with_trace.<locals>.execute\u001b[39m\u001b[34m(ctx)\u001b[39m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(ctx: InvocationContext) -> AsyncGenerator[Event]:\n\u001b[32m    481\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(ctx.agent.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m482\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    483\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/google/adk/agents/base_agent.py:294\u001b[39m, in \u001b[36mBaseAgent.run_async\u001b[39m\u001b[34m(self, parent_context)\u001b[39m\n\u001b[32m    291\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_async_impl(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx.end_invocation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/google/adk/agents/llm_agent.py:460\u001b[39m, in \u001b[36mLlmAgent._run_async_impl\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    458\u001b[39m should_pause = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._llm_flow.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    461\u001b[39m     \u001b[38;5;28mself\u001b[39m.__maybe_save_output_to_state(event)\n\u001b[32m    462\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:370\u001b[39m, in \u001b[36mBaseLlmFlow.run_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    368\u001b[39m last_event = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_one_step_async(invocation_context)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    371\u001b[39m     last_event = event\n\u001b[32m    372\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:447\u001b[39m, in \u001b[36mBaseLlmFlow._run_one_step_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    436\u001b[39m model_response_event = Event(\n\u001b[32m    437\u001b[39m     \u001b[38;5;28mid\u001b[39m=Event.new_id(),\n\u001b[32m    438\u001b[39m     invocation_id=invocation_context.invocation_id,\n\u001b[32m    439\u001b[39m     author=invocation_context.agent.name,\n\u001b[32m    440\u001b[39m     branch=invocation_context.branch,\n\u001b[32m    441\u001b[39m )\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    443\u001b[39m     \u001b[38;5;28mself\u001b[39m._call_llm_async(\n\u001b[32m    444\u001b[39m         invocation_context, llm_request, model_response_event\n\u001b[32m    445\u001b[39m     )\n\u001b[32m    446\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    448\u001b[39m     \u001b[38;5;66;03m# Postprocess after calling the LLM.\u001b[39;00m\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    450\u001b[39m         \u001b[38;5;28mself\u001b[39m._postprocess_async(\n\u001b[32m    451\u001b[39m             invocation_context,\n\u001b[32m   (...)\u001b[39m\u001b[32m    455\u001b[39m         )\n\u001b[32m    456\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m    457\u001b[39m       \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    458\u001b[39m         \u001b[38;5;66;03m# Update the mutable event id to avoid conflict\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:816\u001b[39m, in \u001b[36mBaseLlmFlow._call_llm_async\u001b[39m\u001b[34m(self, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m    813\u001b[39m           \u001b[38;5;28;01myield\u001b[39;00m llm_response\n\u001b[32m    815\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(_call_llm_with_tracing()) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m816\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    817\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:800\u001b[39m, in \u001b[36mBaseLlmFlow._call_llm_async.<locals>._call_llm_with_tracing\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    787\u001b[39m responses_generator = llm.generate_content_async(\n\u001b[32m    788\u001b[39m     llm_request,\n\u001b[32m    789\u001b[39m     stream=invocation_context.run_config.streaming_mode\n\u001b[32m    790\u001b[39m     == StreamingMode.SSE,\n\u001b[32m    791\u001b[39m )\n\u001b[32m    792\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    793\u001b[39m     \u001b[38;5;28mself\u001b[39m._run_and_handle_error(\n\u001b[32m    794\u001b[39m         responses_generator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    798\u001b[39m     )\n\u001b[32m    799\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    801\u001b[39m     trace_call_llm(\n\u001b[32m    802\u001b[39m         invocation_context,\n\u001b[32m    803\u001b[39m         model_response_event.id,\n\u001b[32m    804\u001b[39m         llm_request,\n\u001b[32m    805\u001b[39m         llm_response,\n\u001b[32m    806\u001b[39m     )\n\u001b[32m    807\u001b[39m     \u001b[38;5;66;03m# Runs after_model_callback if it exists.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:1053\u001b[39m, in \u001b[36mBaseLlmFlow._run_and_handle_error\u001b[39m\u001b[34m(self, response_generator, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m   1051\u001b[39m   \u001b[38;5;28;01myield\u001b[39;00m error_response\n\u001b[32m   1052\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1053\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m model_error\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:1039\u001b[39m, in \u001b[36mBaseLlmFlow._run_and_handle_error\u001b[39m\u001b[34m(self, response_generator, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m   1037\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1038\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(response_generator) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m-> \u001b[39m\u001b[32m1039\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m   1040\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m response\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m model_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/google/adk/models/lite_llm.py:1586\u001b[39m, in \u001b[36mLiteLlm.generate_content_async\u001b[39m\u001b[34m(self, llm_request, stream)\u001b[39m\n\u001b[32m   1583\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m aggregated_llm_response_with_tool_call\n\u001b[32m   1585\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1586\u001b[39m   response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.llm_client.acompletion(**completion_args)\n\u001b[32m   1587\u001b[39m   \u001b[38;5;28;01myield\u001b[39;00m _model_response_to_generate_content_response(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/google/adk/models/lite_llm.py:244\u001b[39m, in \u001b[36mLiteLLMClient.acompletion\u001b[39m\u001b[34m(self, model, messages, tools, **kwargs)\u001b[39m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34macompletion\u001b[39m(\n\u001b[32m    230\u001b[39m     \u001b[38;5;28mself\u001b[39m, model, messages, tools, **kwargs\n\u001b[32m    231\u001b[39m ) -> Union[ModelResponse, CustomStreamWrapper]:\n\u001b[32m    232\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Asynchronously calls acompletion.\u001b[39;00m\n\u001b[32m    233\u001b[39m \n\u001b[32m    234\u001b[39m \u001b[33;03m  Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    241\u001b[39m \u001b[33;03m    The model response as a message.\u001b[39;00m\n\u001b[32m    242\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m acompletion(\n\u001b[32m    245\u001b[39m       model=model,\n\u001b[32m    246\u001b[39m       messages=messages,\n\u001b[32m    247\u001b[39m       tools=tools,\n\u001b[32m    248\u001b[39m       **kwargs,\n\u001b[32m    249\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/litellm/utils.py:1646\u001b[39m, in \u001b[36mclient.<locals>.wrapper_async\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1644\u001b[39m timeout = _get_wrapper_timeout(kwargs=kwargs, exception=e)\n\u001b[32m   1645\u001b[39m \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m, timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1646\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/litellm/utils.py:1492\u001b[39m, in \u001b[36mclient.<locals>.wrapper_async\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1489\u001b[39m         print_verbose(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError while checking max token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1491\u001b[39m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1492\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m original_function(*args, **kwargs)\n\u001b[32m   1493\u001b[39m end_time = datetime.datetime.now()\n\u001b[32m   1494\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_streaming_request(\n\u001b[32m   1495\u001b[39m     kwargs=kwargs,\n\u001b[32m   1496\u001b[39m     call_type=call_type,\n\u001b[32m   1497\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/litellm/main.py:626\u001b[39m, in \u001b[36macompletion\u001b[39m\u001b[34m(model, messages, functions, function_call, timeout, temperature, top_p, n, stream, stream_options, stop, max_tokens, max_completion_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, parallel_tool_calls, logprobs, top_logprobs, deployment_id, reasoning_effort, verbosity, safety_identifier, service_tier, base_url, api_version, api_key, model_list, extra_headers, thinking, web_search_options, shared_session, **kwargs)\u001b[39m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    625\u001b[39m     custom_llm_provider = custom_llm_provider \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mopenai\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mexception_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m        \u001b[49m\u001b[43moriginal_exception\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:2340\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m   2338\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exception_mapping_worked:\n\u001b[32m   2339\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mlitellm_response_headers\u001b[39m\u001b[33m\"\u001b[39m, litellm_response_headers)\n\u001b[32m-> \u001b[39m\u001b[32m2340\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   2341\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2342\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m error_type \u001b[38;5;129;01min\u001b[39;00m litellm.LITELLM_EXCEPTION_TYPES:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:429\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m    424\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[32m    425\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minvalid_request_error\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_str\n\u001b[32m    426\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mIncorrect API key provided\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m error_str\n\u001b[32m    427\u001b[39m ):\n\u001b[32m    428\u001b[39m     exception_mapping_worked = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m429\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m BadRequestError(\n\u001b[32m    430\u001b[39m         message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception_provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    431\u001b[39m         llm_provider=custom_llm_provider,\n\u001b[32m    432\u001b[39m         model=model,\n\u001b[32m    433\u001b[39m         response=\u001b[38;5;28mgetattr\u001b[39m(original_exception, \u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    434\u001b[39m         litellm_debug_info=extra_information,\n\u001b[32m    435\u001b[39m         body=\u001b[38;5;28mgetattr\u001b[39m(original_exception, \u001b[33m\"\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    436\u001b[39m     )\n\u001b[32m    437\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[32m    438\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mWeb server is returning an unknown error\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_str\n\u001b[32m    439\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mThe server had an error processing your request.\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_str\n\u001b[32m    440\u001b[39m ):\n\u001b[32m    441\u001b[39m     exception_mapping_worked = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mBadRequestError\u001b[39m: litellm.BadRequestError: OpenAIException - An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_VAoLuJIMMXxjEhhnQJU79njB, call_icc0peXZETWB0HHefBLlK7Xw, call_ZvEQq7QM1Nt5zJAertkjRQQr, call_uBJH2s3aLIhgq56CW4ePgexH, call_rur4SE6ng17L6voZiKeXlVEy"
     ]
    }
   ],
   "source": [
    "await schema_proposal_caller.call(\"How can these files be imported to construct the knowledge graph?\")\n",
    "\n",
    "session_end = await schema_proposal_caller.get_session()\n",
    "\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "print(\"Session state: \", session_end.state)\n",
    "\n",
    "\n",
    "if 'proposed_construction_plan' in session_end.state:\n",
    "    print(\"Proposed construction plan: \", session_end.state['proposed_construction_plan'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804271c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_agent_role_and_goal = \"\"\"\n",
    "    You are an expert at knowledge graph modeling with property graphs. \n",
    "    Criticize the proposed schema for relevance to the user goal and approved files.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8056af16",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_agent_hints = \"\"\"\n",
    "    Criticize the proposed schema for relevance and correctness:\n",
    "    - Are unique identifiers actually unique? Use the 'search_file' tool to validate. Composite identifier are not acceptable.\n",
    "    - Could any nodes be relationships instead? Double-check that unique identifiers are unique and not references to other nodes. Use the 'search_file' tool to validate\n",
    "    - Can you manually trace through the source data to find the necessary information for anwering a hypothetical question?\n",
    "    - Is every node in the schema connected? What relationships could be missing? Every node should connect to at least one other node.\n",
    "    - Are hierarchical container relationships missing? \n",
    "    - Are any relationships redundant? A relationship between two nodes is redundant if it is semantically equivalent to or the inverse of another relationship between those two nodes.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feef2e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_agent_chain_of_thought_directions = \"\"\"\n",
    "    Prepare for the task:\n",
    "    - get the user goal using the 'get_approved_user_goal' tool\n",
    "    - get the list of approved files using the 'get_approved_files' tool\n",
    "    - get the construction plan using the 'get_proposed_construction_plan' tool\n",
    "    - use the 'sample_file' and 'search_file' tools to validate the schema design\n",
    "\n",
    "    Think carefully, using tools to perform actions and reconsidering your actions when a tool returns an error:\n",
    "    1. Analyze each construction rule in the proposed construction plan.\n",
    "    2. Use tools to validate the construction rules for relevance and correctness.\n",
    "    3. If the schema looks good, respond with a one word reply: 'valid'.\n",
    "    4. If the schema has problems, respond with 'retry' and provide feedback as a concise bullet list of problems.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfadcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    You are an expert at knowledge graph modeling with property graphs. \n",
      "    Criticize the proposed schema for relevance to the user goal and approved files.\n",
      "\n",
      "\n",
      "    Criticize the proposed schema for relevance and correctness:\n",
      "    - Are unique identifiers actually unique? Use the 'search_file' tool to validate. Composite identifier are not acceptable.\n",
      "    - Could any nodes be relationships instead? Double-check that unique identifiers are unique and not references to other nodes. Use the 'search_file' tool to validate\n",
      "    - Can you manually trace through the source data to find the necessary information for anwering a hypothetical question?\n",
      "    - Is every node in the schema connected? What relationships could be missing? Every node should connect to at least one other node.\n",
      "    - Are hierarchical container relationships missing? \n",
      "    - Are any relationships redundant? A relationship between two nodes is redundant if it is semantically equivalent to or the inverse of another relationship between those two nodes.\n",
      "\n",
      "\n",
      "    Prepare for the task:\n",
      "    - get the user goal using the 'get_approved_user_goal' tool\n",
      "    - get the list of approved files using the 'get_approved_files' tool\n",
      "    - get the construction plan using the 'get_proposed_construction_plan' tool\n",
      "    - use the 'sample_file' and 'search_file' tools to validate the schema design\n",
      "\n",
      "    Think carefully, using tools to perform actions and reconsidering your actions when a tool returns an error:\n",
      "    1. Analyze each construction rule in the proposed construction plan.\n",
      "    2. Use tools to validate the construction rules for relevance and correctness.\n",
      "    3. If the schema looks good, respond with a one word reply: 'valid'.\n",
      "    4. If the schema has problems, respond with 'retry' and provide feedback as a concise bullet list of problems.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# combine all the prompt parts together\n",
    "critic_agent_instruction = f\"\"\"\n",
    "{critic_agent_role_and_goal}\n",
    "{critic_agent_hints}\n",
    "{critic_agent_chain_of_thought_directions}\n",
    "\"\"\"\n",
    "\n",
    "print(critic_agent_instruction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5776b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_approved_user_goal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m schema_critic_agent_tools = [\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mget_approved_user_goal\u001b[49m, get_approved_files,\n\u001b[32m      3\u001b[39m     get_proposed_construction_plan,\n\u001b[32m      4\u001b[39m     sample_file, search_file\n\u001b[32m      5\u001b[39m ]\n",
      "\u001b[31mNameError\u001b[39m: name 'get_approved_user_goal' is not defined"
     ]
    }
   ],
   "source": [
    "schema_critic_agent_tools = [\n",
    "    get_approved_user_goal, get_approved_files,\n",
    "    get_proposed_construction_plan,\n",
    "    sample_file, search_file\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aede98b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRITIC_NAME = \"schema_critic_agent_v1\"\n",
    "schema_critic_agent = LlmAgent(\n",
    "    name=CRITIC_NAME,\n",
    "    description=\"Criticizes the proposed schema for relevance to the user goal and approved files.\",\n",
    "    model=llm,\n",
    "    instruction=critic_agent_instruction,\n",
    "    tools=schema_critic_agent_tools, \n",
    "    output_key=\"feedback\", # specify the context state key which will contain the result of calling the critic,\n",
    "    before_agent_callback=log_agent\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c7f6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.agents.invocation_context import InvocationContext\n",
    "from google.adk.agents.base_agent import BaseAgent\n",
    "from google.adk.events import Event, EventActions\n",
    "from typing import AsyncGenerator\n",
    "\n",
    "class CheckStatusAndEscalate(BaseAgent):\n",
    "    async def _run_async_impl(self, ctx: InvocationContext) -> AsyncGenerator[Event, None]:\n",
    "        feedback = ctx.session.state.get(\"feedback\", \"valid\")\n",
    "        should_stop = (feedback == \"valid\")\n",
    "        yield Event(author=self.name, actions=EventActions(escalate=should_stop))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e60c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_refinement_loop = LoopAgent(\n",
    "    name=\"schema_refinement_loop\",\n",
    "    description=\"Analyzes approved files to propose a schema based on user intent and feedback\",\n",
    "    max_iterations=2,\n",
    "    sub_agents=[schema_proposal_agent, schema_critic_agent, CheckStatusAndEscalate(name=\"StopChecker\")],\n",
    "    before_agent_callback=log_agent\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008ccf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import make_agent_caller\n",
    "\n",
    "# NOTE: this may take some time to run, and may require further iterations to satisfy the critic!\n",
    "refinement_loop_caller = await make_agent_caller(schema_refinement_loop, {\n",
    "    \"feedback\": \"\",\n",
    "    \"approved_user_goal\": {\n",
    "        \"kind_of_graph\": \"supply chain analysis\",\n",
    "        \"description\": \"A multi-level bill of materials for manufactured products, useful for root cause analysis..\"\n",
    "    },\n",
    "    \"approved_files\": [\n",
    "        'products.csv', \n",
    "        'assemblies.csv', \n",
    "        'parts.csv', \n",
    "        'part_supplier_mapping.csv', \n",
    "        'suppliers.csv'\n",
    "    ]\n",
    "})\n",
    "\n",
    "await refinement_loop_caller.call(\"How can these files be imported?\")\n",
    "\n",
    "# Alternatively, you can uncomment the line below to run the refinement loop with verbose output\n",
    "# await refinement_loop_caller.call(\"How can these files be imported?\", True)\n",
    "\n",
    "session_end = await refinement_loop_caller.get_session()\n",
    "print(\"Session state: \", session_end.state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be257ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
